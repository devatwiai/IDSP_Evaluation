{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import json\n",
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EventExtractionEvaluation:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.synonyms = json.load(open(\"/home/ubuntu/devesh/Prod_changes/idsp_feb_5th/idsp-score/data/05_model_input/disease_synonyms.json\"))\n",
    "        \n",
    "    def group_diseases(self, events):\n",
    "        new_events = []\n",
    "        for event in events:\n",
    "            disease = event[\"disease\"]\n",
    "            for key in self.synonyms.keys():\n",
    "                synonyms_for_disease = [x.lower() for x in self.synonyms[key]]\n",
    "                if disease.lower().lstrip().rstrip() in synonyms_for_disease:\n",
    "                    event[\"disease\"] = key.lower()\n",
    "                    event[\"original_disease\"] = disease\n",
    "                    break  \n",
    "            new_events.append(event)\n",
    "        return new_events\n",
    "\n",
    "    def precision_recall_method_1(self, pred, gt):\n",
    "        \n",
    "\n",
    "        gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "        pred = set(tuple(sorted(d.items())) for d in pred)\n",
    "        \n",
    "        tp = len(pred.intersection(gt))\n",
    "        fp = len(pred.difference(gt))\n",
    "        fn = len(gt.difference(pred))\n",
    "\n",
    "        precision = tp / (tp + fp) if tp+fp > 0 else 1.0\n",
    "        recall = tp / (tp + fn) if (tp+fn) > 0 else 1.0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 1.0\n",
    "        exact_match = 1.0 if pred == gt else 0.0\n",
    "        \n",
    "        return precision, recall, f1, exact_match\n",
    "        \n",
    "    def precision_recall_method_2(self, pred, gt):\n",
    "         \n",
    "        # strip spaces from the values\n",
    "        # for d in gt:\n",
    "        #     for k, v in d.items():\n",
    "        #         d[k] = v.strip()\n",
    "        # for d in pred:\n",
    "        #     for k, v in d.items():\n",
    "        #         d[k] = v.strip()\n",
    "        try:\n",
    "            pred = set(tuple(sorted(d.items())) for d in pred)    \n",
    "        except:\n",
    "            print('pred: ', pred) \n",
    "            pred = set([])\n",
    "            \n",
    "        gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "        tp = len(pred.intersection(gt))\n",
    "        fp = len(pred.difference(gt))\n",
    "        fn = len(gt.difference(pred))\n",
    "        \n",
    "        \n",
    "            \n",
    "        if tp == 0 and fp == 0 and fn == 0:\n",
    "            precision = 1.0; recall = 1.0; f1 = 1.0\n",
    "        elif tp == 0 and (fp > 0 or fn > 0):\n",
    "            precision = 0.0; recall = 0.0; f1 = 0.0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        exact_match = 1.0 if pred == gt else 0.0\n",
    "        \n",
    "        # write incorrect predictions to a file\n",
    "        ptr = open('incorrect_predictions_gpt3.5.txt', 'a')\n",
    "        if exact_match == 0:\n",
    "            ptr.write('GT: ' + str(gt) + '\\n')\n",
    "            ptr.write('Pred: ' + str(pred) + '\\n\\n')\n",
    "            \n",
    "        \n",
    "        return precision, recall, f1, exact_match\n",
    "\n",
    "\n",
    "    def jaccard_index(self, pred, gt):\n",
    "        \n",
    "        try:\n",
    "            pred = set(tuple(sorted(d.items())) for d in pred)    \n",
    "        except:\n",
    "            pred = set([])\n",
    "            \n",
    "        gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "        if len(pred) == 0 and len(gt) == 0: return 1\n",
    "        intersection = len(pred.intersection(gt))\n",
    "        union = len(pred.union(gt))\n",
    "        return intersection / union\n",
    "    \n",
    "\n",
    "    def subset_accuracy(self, pred, gt):\n",
    "        \n",
    "        try:\n",
    "            pred = set(tuple(sorted(d.items())) for d in pred)    \n",
    "        except:\n",
    "            print('pred: ', pred) \n",
    "            pred = set([])\n",
    "            \n",
    "        gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "        return float(pred.issubset(gt))\n",
    "\n",
    "    def evaluate_event_extraction(self):\n",
    "        # Group diseases using synonyms list\n",
    "        self.df['GT_Events'] = self.df['GT_Events'].apply(lambda events: self.group_diseases(events))\n",
    "        self.df['events'] = self.df['events'].apply(lambda events: self.group_diseases(events))\n",
    "        \n",
    "        # if 'number' not present as a key in the GT_events or events make 'number': ''\n",
    "        self.df['GT_Events'] = self.df['GT_Events'].apply(lambda x: [{k: v for k, v in i.items()} if 'number' in i.keys() else {**i, 'number': ''} for i in x])\n",
    "        self.df['events'] = self.df['events'].apply(lambda x: [{k: v for k, v in i.items()} if 'number' in i.keys() else {**i, 'number': ''} for i in x])\n",
    "        \n",
    "        \n",
    "        def keys_to_keep(d):\n",
    "            return {k: v for k, v in d.items() if k in ['disease', 'location', 'incident', 'incident_type', 'number']}\n",
    "        self.df['GT_Events'] = self.df['GT_Events'].apply(lambda x: [keys_to_keep(i) for i in x])\n",
    "        self.df['events'] = self.df['events'].apply(lambda x: [keys_to_keep(i) for i in x])\n",
    "\n",
    "\n",
    "        \n",
    "        # apply precision_recall_method_2 to each row\n",
    "        self.df['precision'], self.df['recall'], self.df['f1'], self.df['exact_match'] = zip(*self.df.apply(lambda row: self.precision_recall_method_2(row['events'], row['GT_Events']), axis=1))\n",
    "        self.df['jaccard'] = self.df.apply(lambda row: self.jaccard_index(row['events'], row['GT_Events']), axis=1)\n",
    "        self.df['subset'] = self.df.apply(lambda row: self.subset_accuracy(row['events'], row['GT_Events']), axis=1)\n",
    "        \n",
    "        metrics = {\n",
    "            \"precision\": self.df['precision'].mean(),\n",
    "            \"recall\": self.df['recall'].mean(),\n",
    "            \"f1\": self.df['f1'].mean(),\n",
    "            \"exact_match\": self.df['exact_match'].mean(),\n",
    "            \"jaccard\": self.df['jaccard'].mean(),\n",
    "            \"subset\": self.df['subset'].mean()\n",
    "        }\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LLMEventFilterer:\n",
    "    def __init__(self, disease_syn_path):\n",
    "        self.disease_synonyms = json.load(open(disease_syn_path))\n",
    "        # Define the keys to filter\n",
    "        self. target_keys = {'Disease', 'Location', 'Incident (case or death)', 'Incident Type (new or total)', 'Number'}\n",
    "\n",
    "    def lower_case_keys(self, d):\n",
    "        return {k.lower(): v.lower() if isinstance(v, str) else v for k, v in d.items()}\n",
    "    \n",
    "    # Function to filter rows based on keys\n",
    "    def filter_rows(self, row, target_keys):\n",
    "        target_keys = sorted(target_keys)\n",
    "        try:\n",
    "            events = []\n",
    "            for event in row:\n",
    "                keys = sorted(event.keys())\n",
    "                if keys == target_keys:\n",
    "                    events.append(event)\n",
    "                else:\n",
    "                    continue\n",
    "            return events\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "            return []\n",
    "\n",
    "    def map_keys(self, events):\n",
    "        new_events = []\n",
    "        for event in events:\n",
    "            new_event = {\n",
    "                \"Incident Type (new or total)\": event.get('Incident Type (total or new)', event.get('Incident Type (new or total)', event.get('Incident Type (total)', event.get('Incident (new)', event.get('Incident', ''))))),\n",
    "                \"Incident (case or death)\": event.get('Incident (cases or deaths)', event.get(\"Incident Type (case or death)\", event.get('Incident (case or death)', ''))),\n",
    "                \"Location\": event.get('Location', ''),\n",
    "                \"Disease\": event.get('Disease', '')\n",
    "            }\n",
    "            if 'Number' in event.keys():\n",
    "                new_event[\"Number\"] = event[\"Number\"]\n",
    "            new_events.append(new_event)\n",
    "        return new_events \n",
    "    \n",
    "    def group_diseases(self, events):\n",
    "        try:\n",
    "            new_events = []\n",
    "            for event in events:\n",
    "                disease = event[\"disease\"]\n",
    "                for key in self.disease_synonyms.keys():\n",
    "                    synonyms_for_disease = [x.lower() for x in self.disease_synonyms[key]]\n",
    "                    if disease.lower().lstrip().rstrip() in synonyms_for_disease:\n",
    "                        event[\"disease\"] = key\n",
    "                        event[\"original_disease\"] = disease  # storing original disease to be used after post-processing\n",
    "                if \"original_disease\" not in event.keys():  # keep the original string.\n",
    "                    event[\"original_disease\"] = \"\"\n",
    "                \n",
    "                new_events.append(event)\n",
    "                \n",
    "            return new_events\n",
    "        except:\n",
    "            return events\n",
    "    \n",
    "    def filter_events(self, response):\n",
    "        try: \n",
    "            if response:\n",
    "                start = response.find(\"[{\")\n",
    "                end = response.find(\"}]\")\n",
    "                if start != -1 and end != -1:\n",
    "                    events = response[start : end+2]\n",
    "                    return events\n",
    "                else:\n",
    "                    return '[]'\n",
    "            else:\n",
    "                return '[]'\n",
    "        except:\n",
    "            return '[]'\n",
    "        \n",
    "\n",
    "    def safe_eval(self, x):\n",
    "        try:\n",
    "            return eval(x)\n",
    "        except SyntaxError:\n",
    "            return []  # Return None for rows with invalid syntax\n",
    "\n",
    "            \n",
    "    def filter_number(self, events):\n",
    "        new_events = []\n",
    "       # conver string to number\n",
    "        try:\n",
    "            for event in events:\n",
    "                if event[\"Number\"]:\n",
    "                    event[\"Number\"] = str(w2n.word_to_num(event[\"Number\"]))\n",
    "                else:\n",
    "                    event[\"Number\"] = ''\n",
    "                new_events.append(event)\n",
    "            return new_events\n",
    "        except Exception as e:\n",
    "            return events\n",
    "        \n",
    "    def filter_unknown_na(self, events_str):\n",
    "        # Replacing 'N/A', 'null', 'Unknown', 'unknown' with empty string\n",
    "        events_str = events_str.replace('N/A', '').replace('null', '').replace('Unknown', '').replace('unknown', '')\n",
    "        return events_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of non empty events: 684\n",
      "Total no of non empty GT events: 849\n",
      "Total no of non empty events: 10\n",
      "Total no of non empty GT events: 133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.5014965986394558,\n",
       " 'recall': 0.5044444444444445,\n",
       " 'f1': 0.4977196650666038,\n",
       " 'exact_match': 0.4340136054421769,\n",
       " 'jaccard': 0.4796016039893591,\n",
       " 'subset': 0.5401360544217687}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_syn_path = \"/home/ubuntu/devesh/Prod_changes/idsp_feb_5th/idsp-score/data/05_model_input/disease_synonyms.json\"\n",
    "event_filterer = LLMEventFilterer(disease_syn_path)\n",
    "\n",
    "numbered_df = pd.read_csv('./output_llama_finetuned_numbered_lora.csv')\n",
    "numberless_df = pd.read_csv('./llama_empty_numberless_lora.csv')\n",
    "\n",
    "# remove irrelevant rows\n",
    "irrelevant_df = pd.read_csv('articles_irrelevant.csv')\n",
    "irrelevant_articles = irrelevant_df['Article'].tolist()\n",
    "numbered_df = numbered_df[~numbered_df['Article'].isin(irrelevant_articles)]\n",
    "numberless_df = numberless_df[~numberless_df['Article'].isin(irrelevant_articles)]\n",
    "\n",
    "\n",
    "def preprocess_data(df, numberless=False):\n",
    "    df['events'] = df['Generated_Events']\n",
    "    if numberless:\n",
    "        df['events'] = df['Generated_Events']\n",
    "\n",
    "    df['events'] = df['events'].fillna('')\n",
    "    df['events'] = df['events'].apply(event_filterer.filter_events)\n",
    "    df['events'] = df['events'].apply(event_filterer.filter_unknown_na)\n",
    "    df['events'] = df['events'].apply(event_filterer.safe_eval)\n",
    "    df['events'] = df['events'].apply(event_filterer.map_keys)\n",
    "\n",
    "    if numberless is False:\n",
    "        df['events'] = df['events'].apply(lambda x: event_filterer.filter_rows(x, {'Disease', 'Location', 'Incident (case or death)', 'Incident Type (new or total)', 'Number'}))\n",
    "    else:\n",
    "        df['events'] = df['events'].apply(lambda x: event_filterer.filter_rows(x, {'Disease', 'Location', 'Incident (case or death)', 'Incident Type (new or total)'}))\n",
    "\n",
    "    df['events'] = df['events'].apply(event_filterer.filter_number)\n",
    "    df['GT_Events'] = df['GT_Events'].apply(event_filterer.safe_eval)\n",
    "\n",
    "    # convert keys to lower case \n",
    "    df['events'] = df['events'].apply(lambda x: [event_filterer.lower_case_keys(i) for i in x])\n",
    "    df['GT_Events'] = df['GT_Events'].apply(lambda x: [event_filterer.lower_case_keys(i) for i in x])\n",
    "\n",
    "    print('Total no of non empty events:', df['events'].apply(len).sum())\n",
    "    print('Total no of non empty GT events:', df['GT_Events'].apply(len).sum())\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "numbered_df = preprocess_data(numbered_df)\n",
    "numberless_df = preprocess_data(numberless_df, numberless=True)\n",
    "# articles for which numbered events are empty, check if they are present in numberless_df\n",
    "empty_events = numbered_df[numbered_df['events'].apply(len) == 0]\n",
    "empty_articles = empty_events['Article'].tolist()\n",
    "# write empty_events df to csv\n",
    "empty_events.to_csv('empty_events-llama_numbered_lora.csv', index=False)\n",
    "\n",
    "numberless_df = numberless_df[numberless_df['Article'].isin(empty_articles)]\n",
    "def update_events(row, numberless_df):\n",
    "    if len(row['events']) == 0:\n",
    "        filtered_df = numberless_df[numberless_df['Article'] == row['Article']]\n",
    "        if not filtered_df.empty:\n",
    "            return filtered_df['events'].values[0]\n",
    "    return row['events']\n",
    "\n",
    "numbered_df['events'] = numbered_df.apply(lambda row: update_events(row, numberless_df), axis=1)\n",
    "\n",
    "# write filtered events to csv as 'Filtered_llama_finetuned.csv'\n",
    "\n",
    "\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "qa_only_results = {}\n",
    "df_copy = numbered_df.copy()\n",
    "event_eval = EventExtractionEvaluation(df_copy.copy())\n",
    "metrics = event_eval.evaluate_event_extraction()\n",
    "\n",
    "# keep only relevant columns: Article, GT_Events, events\n",
    "\n",
    "numbered_df.to_csv('Filtered_llama_finetuned.csv', index=False)\n",
    "\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
