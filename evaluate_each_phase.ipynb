{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.idsp_kedro.pipelines.disease_ner.disease_ner_nodes import DiseaseTagger\n",
    "from src.idsp_kedro.pipelines.relevancy_classifier.nodes import RelevanceTagger\n",
    "from src.idsp_kedro.pipelines.translate.nodes import Translator\n",
    "from src.idsp_kedro.pipelines.event_extraction.extraction_nodes import EventExtractor\n",
    "from src.idsp_kedro.pipelines.location_date_ner.nodes import LocationDateTagger\n",
    "from src.idsp_kedro.pipelines.event_extraction.filtering_nodes import EventFilterer\n",
    "from src.idsp_kedro.pipelines.noevents_extraction.extraction_nodes import NoEventExtractorNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './750_annotated_articles.csv'\n",
    "main_df = pd.read_csv(path, encoding='utf-8', lineterminator='\\n')  \n",
    "print('len of main_df:', main_df.shape[0])\n",
    "\n",
    "main_df['GT_Events'] = main_df['GT_Events'].apply(eval)\n",
    "main_df = main_df[main_df['Article'].notnull()]\n",
    "main_df.reset_index(drop=True, inplace=True)\n",
    "print('Number of Articles after removing empty articles:', main_df.shape[0])\n",
    "\n",
    "N_no_events = sum(main_df['GT_Events'].apply(lambda x: 0 if len(x) else 1))\n",
    "N_events = main_df.shape[0] - N_no_events\n",
    "\n",
    "main_df['complete_article'] = main_df['Article'].copy()\n",
    "main_df['lang'] = 'en'\n",
    "print('Articles with atleast one Event:', N_events)\n",
    "print('Number of no event Articles:', N_no_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = main_df['GT_Events'].apply(len).value_counts().sort_index()\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=histogram.index, y=histogram.values, palette=\"Blues_d\")\n",
    "ax.set(xlabel='Number of Events', ylabel='Number of Articles')\n",
    "# write value on top of each bar\n",
    "for i in range(len(histogram)):\n",
    "    ax.text(i, histogram.values[i], histogram.values[i], ha = 'center')\n",
    "plt.title('Number of Events per Article')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self):\n",
    "        self.params = yaml.safe_load(open(\"/home/ubuntu/devesh/Prod_change_12th_jan/idsp_5th_feb/idsp-score/conf/local/parameters.yml\"))\n",
    "        self.params[\"common_params\"][\"lang_dict\"] = \"/home/ubuntu/devesh/Prod_change_12th_jan/idsp_5th_feb/idsp-score/data/05_model_input/lang_dict.json\"\n",
    "        self.device_params = self.params[\"device_params\"]\n",
    "        self.common_params = self.params[\"common_params\"]\n",
    "        \n",
    "        \n",
    "    def language_classifier(self, df):\n",
    "        df['lang'] = df['Original_Article'].apply(lambda x: langid.classify(x)[0])\n",
    "        return df\n",
    "    \n",
    "    def relevancy_classifier(self, df):\n",
    "        \n",
    "        print('Relevancy Classifier...')\n",
    "        relevance_params = self.params[\"relevance_params\"]\n",
    "        relevance_tagger_obj = RelevanceTagger(\n",
    "                 relevance_params, self.device_params, self.common_params\n",
    "         )        \n",
    "        # we don't have title and description separate, we perform it on the whole article one by one\n",
    "        def get_relevance_per_article(article, lang, threshold=0.5):\n",
    "            pred_article, confidence = relevance_tagger_obj.get_relevance_per_article(article=article, lang=lang)\n",
    "            return pred_article, confidence\n",
    "\n",
    "        relevancy_preds = []\n",
    "        confidence_preds = []\n",
    "        for itr, article in enumerate(df['Original_Article']):\n",
    "            relevancy, confidence = get_relevance_per_article(article, df['lang'][itr])\n",
    "            relevancy_preds.append(relevancy)\n",
    "            confidence_preds.append(confidence)\n",
    "\n",
    "        df['relevant'] = [1 if i == 1 else 0 for i in relevancy_preds]\n",
    "  \n",
    "        return df, confidence_preds\n",
    "    \n",
    "    def translate(self, df):\n",
    "        translator_obj = Translator(common_params=self.common_params)\n",
    "        translated_articles, avg_time_per_lang_per_word = translator_obj.run_translate_to_en(articles=df['Original_Article'])\n",
    "        df['complete_article'] = translated_articles\n",
    "        df['lang'] = 'en'\n",
    "\n",
    "        return df, avg_time_per_lang_per_word\n",
    "    \n",
    "    def disease_ner(self, df):\n",
    "        \n",
    "        print('Disease NER...')\n",
    "        disease_tagger_obj = DiseaseTagger(\n",
    "        disease_ner_params=self.params[\"disease_ner_params\"],\n",
    "        device_params=self.params[\"device_params\"],\n",
    "        common_params=self.params[\"common_params\"])\n",
    "        disease_pred = []\n",
    "        articles = df['complete_article']\n",
    "        \n",
    "        df = disease_tagger_obj.perform_disease_ner_on_df(df)\n",
    "        \n",
    "        return df\n",
    "      \n",
    "    def location_ner(self, df):\n",
    "        print('Location NER...')\n",
    "        location_tagger_obj = LocationDateTagger(\n",
    "            ner_params=self.params[\"location_date_ner_params\"],\n",
    "            common_params=self.params[\"common_params\"])\n",
    "        \n",
    "        df = location_tagger_obj.get_location_date_for_df(df)    \n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def qa(self, df):\n",
    "        print('QA...')\n",
    "        event_extractor_obj = EventExtractor(\n",
    "            event_ext_params=self.params[\"event_extraction_params\"],\n",
    "            device_params=self.device_params,\n",
    "            common_params=self.common_params,\n",
    "        )\n",
    "        event_filter_obj = EventFilterer(common_params=self.common_params)\n",
    "        total_events_list = event_extractor_obj.perform_event_extraction(df, preprocess=False)\n",
    "        df = event_filter_obj.filter_events_df(df, total_events_list)\n",
    "        return df\n",
    "\n",
    "        \n",
    "    def nli(self, df):\n",
    "        print('Numberless Event Extraction...')\n",
    "        noevent_extraction_params=self.params[\"noevent_extraction_params\"]\n",
    "        noevent_ext_obj = NoEventExtractorNLI(noevent_extraction_params,\n",
    "                                              self.device_params,\n",
    "                                              self.common_params)\n",
    "        \n",
    "        total_events_list = noevent_ext_obj.perform_noevent_extraction_and_filter(df, preprocess=False)\n",
    "        df[\"noevents_events\"] = total_events_list\n",
    "        \n",
    "        return df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation only\n",
    "pipeline = Pipeline()\n",
    "df, avg_time_per_lang_per_word = pipeline.translate(main_df)\n",
    "# rename complete article to indictransv2_article\n",
    "df.rename(columns={'complete_article': 'indictransv2_article'}, inplace=True)\n",
    "df.to_csv('750_translated_articles_indictransv2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline()\n",
    "# Relevancy Classifier\n",
    "\n",
    "df, _ = pipeline.relevancy_classifier(main_df)\n",
    "\n",
    "# Disease NER\n",
    "df = pipeline.disease_ner(df)\n",
    "df['disease_pred'] = df['disease_pred'].apply(lambda x: ', '.join([i.lower() for i in x]))\n",
    "df['disease_by_keyword_spotting'] = df['disease_by_keyword_spotting'].apply(lambda x: ', '.join([i.lower() for i in x]))\n",
    "df['disease_by_ner'] = df['disease_by_ner'].apply(lambda x: ', '.join([i.lower() for i in x]))\n",
    "# Copy diseases from GT for QA and NLI\n",
    "df['diseases'] = df['GT_Events'].apply(lambda x: [i['Disease'] for i in x])\n",
    "df['diseases'] = df['diseases'].apply(lambda x: ', '.join([i for i in x]))\n",
    "df['diseases'] = df['diseases'].apply(lambda x: ', '.join(set(x.split(', '))))\n",
    "\n",
    "# Location NER\n",
    "df = pipeline.location_ner(df)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.rename(columns={'location': 'locations_pred'})\n",
    "df = df.rename(columns={'dates': 'dates_pred'})\n",
    "df['date'] = ''\n",
    "# Copy locations from GT for QA and NLI\n",
    "df['location'] = df['GT_Events'].apply(lambda x: [i['Location'] for i in x])\n",
    "df['location'] = df['location'].apply(lambda x: ', '.join([i.lower() for i in x]))\n",
    "df['location'] = df['location'].apply(lambda x: ', '.join(set(x.split(', '))))\n",
    "# for each location copy it to a tuple, for example: india, kerala - [(india, india), (kerala, kerala)]\n",
    "df['location'] = df['location'].apply(lambda x: [(i, i) for i in x.split(', ') if len(i)])\n",
    "\n",
    "# QA\n",
    "df = pipeline.qa(df)\n",
    "df.loc[:,\"old_data_cluster_idx\"] = ''\n",
    "\n",
    "# NLI\n",
    "df = pipeline.nli(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevancy Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Relevancy Classifer  \n",
    "\n",
    "def evaluate_relevancy(df):\n",
    "    print('Total number of articles:', len(df))\n",
    "    df['gt'] = df['GT_Events'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "    tp = sum((df['gt'] == 1) & (df['relevant'] == 1))\n",
    "    fp = sum((df['gt'] == 0) & (df['relevant'] == 1))\n",
    "    fn = sum((df['gt'] == 1) & (df['relevant'] == 0))\n",
    "    tn = sum((df['gt'] == 0) & (df['relevant'] == 0))\n",
    "    \n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn)/(tp + fp + tn + fn)\n",
    "    \n",
    "    tpr = recall\n",
    "    fpr = fp / (fp + tn)\n",
    "    \n",
    "    return precision, recall, f1, accuracy, tpr, fpr\n",
    "    \n",
    "\n",
    "# Relevancy Classifier\n",
    "pipeline = Pipeline()\n",
    "precision_list = []; recall_list = []; f1_list = []; accuracy_list = []\n",
    "df = pipeline.language_classifier(main_df)\n",
    "df, confidence_preds = pipeline.relevancy_classifier(df)\n",
    "precision, recall, f1, accuracy, tpr, fpr = evaluate_relevancy(df)\n",
    "precision_list.append(precision)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)\n",
    "accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision, recall, f1, accuracy based on language df['lang'] for each language\n",
    "for lang in ['en', 'hi', 'te']:\n",
    "    df_lang = df[df['lang'] == lang]\n",
    "    precision, recall, f1, accuracy, tpr, fpr = evaluate_relevancy(df_lang)\n",
    "    print(f'Lang: {lang}, Precision: {precision}, Recall: {recall}, F1: {f1}, Accuracy: {accuracy}, TPR: {tpr}, FPR: {fpr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "# confidence_preds = np.array(confidence_preds)[:, 1:].squeeze()\n",
    "gt = np.array(df['gt'])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(gt, confidence_preds)\n",
    "roc_auc = metrics.auc(fpr, tpr) \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print('AUC:', roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get confusion matrix at 0.5 threshold\n",
    "threshold = 0.5\n",
    "pred = [1 if i > threshold else 0 for i in confidence_preds]\n",
    "confusion_matrix = metrics.confusion_matrix(gt, pred)\n",
    "print('Confusion Matrix at 0.5 threshold:', confusion_matrix)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1:', f1)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# plot confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy diseases from GT for QA and NLI\n",
    "df = main_df.copy()\n",
    "# keep only those articles where events are present\n",
    "df = df[df['GT_Events'].apply(len) > 0]\n",
    "df = df.reset_index(drop=True)\n",
    "print('Total number of articles:', len(df))\n",
    "df['diseases'] = df['GT_Events'].apply(lambda x: [i['Disease'] for i in x])\n",
    "df['diseases'] = df['diseases'].apply(lambda x: ', '.join([i for i in x]))\n",
    "df['diseases'] = df['diseases'].apply(lambda x: ', '.join(set(x.split(', '))))\n",
    "\n",
    "df['date'] = ''\n",
    "# Copy locations from GT for QA and NLI\n",
    "df['location'] = df['GT_Events'].apply(lambda x: [i['Location'] for i in x])\n",
    "df['location'] = df['location'].apply(lambda x: ', '.join([i.lower() for i in x]))\n",
    "df['location'] = df['location'].apply(lambda x: ', '.join(set(x.split(', '))))\n",
    "\n",
    "print('Total no of non empty GT events:', df['GT_Events'].apply(len).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.safe_load(open(\"/home/ubuntu/devesh/Prod_change_12th_jan/idsp_5th_feb/idsp-score/conf/local/parameters.yml\"))\n",
    "params[\"common_params\"][\"lang_dict\"] = \"/home/ubuntu/devesh/Prod_change_12th_jan/idsp_5th_feb/idsp-score/data/05_model_input/lang_dict.json\"\n",
    "device_params = params[\"device_params\"]\n",
    "common_params = params[\"common_params\"]\n",
    "\n",
    "event_extractor_obj = EventExtractor(\n",
    "                event_ext_params=params[\"event_extraction_params\"],\n",
    "                device_params=device_params,\n",
    "                common_params=common_params,\n",
    "                )\n",
    "         \n",
    "tp = 0; fp = 0; fn = 0; tn = 0\n",
    "excact_match = 0; total_numbered_events = 0; no_ans = 0; incorrect_ans = 0\n",
    "for i in range(df.shape[0]):\n",
    "    article = df['complete_article'][i]\n",
    "    events = df['GT_Events'][i]\n",
    "    for event in events:\n",
    "        if event['Number'] == '': # consider only numbered events\n",
    "            continue\n",
    "        \n",
    "        incident_type = event['Incident Type (new or total)']\n",
    "        case_or_death = event['Incident (case or death)']\n",
    "        row = pd.Series()\n",
    "        row[\"complete_article\"] = article\n",
    "        row[\"location\"] = [(event['Location'], event['Location'])]\n",
    "        row[\"date\"] = None\n",
    "        row[\"diseases\"] = event['Disease']\n",
    "        row[\"lang\"] = 'en'\n",
    "        total_numbered_events += 1\n",
    "        events_list = event_extractor_obj.perform_event_extraction_per_article(row, incident_type, case_or_death)\n",
    "        if len(events_list) > 1:\n",
    "            print('More than one event:', events_list)\n",
    "        \n",
    "        \n",
    "# Print results\n",
    "# print('Total Numbered Events:', total_numbered_events)\n",
    "# print('Exact Match:', excact_match)\n",
    "# print('No Answer:', no_ans)\n",
    "# print('Incorrect Answer:', incorrect_ans)\n",
    "# print('Accuracy:', excact_match/total_numbered_events)\n",
    "# print('No Answer Percentage:', no_ans/total_numbered_events)\n",
    "# print('Incorrect Answer Percentage:', incorrect_ans/total_numbered_events)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = main_df.copy()\n",
    "df = df[df['GT_Events'].apply(len) > 0]\n",
    "df = df.reset_index(drop=True)\n",
    "# print total number of events\n",
    "print('Total Number of Events:', df['GT_Events'].apply(len).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.safe_load(open(\"/home/ubuntu/devesh/Prod_change_12th_jan/idsp_5th_feb/idsp-score/conf/local/parameters.yml\"))\n",
    "params[\"common_params\"][\"lang_dict\"] = \"/home/ubuntu/devesh/Prod_change_12th_jan/idsp_5th_feb/idsp-score/data/05_model_input/lang_dict.json\"\n",
    "device_params = params[\"device_params\"]\n",
    "common_params = params[\"common_params\"]\n",
    "noevent_extraction_params=params[\"noevent_extraction_params\"]\n",
    "noevent_ext_obj = NoEventExtractorNLI(noevent_extraction_params,\n",
    "                                device_params,\n",
    "                                common_params)\n",
    "         \n",
    "correct = 0; total = 0\n",
    "print(len(df))\n",
    "for i in range(len(df)):\n",
    "    article = df['complete_article'][i]\n",
    "    events = df['GT_Events'][i]\n",
    "    for event in events:        \n",
    "        if event['Number'] != '': # consider only no numbered events\n",
    "                continue\n",
    "        case_or_death = event['Incident (case or death)']\n",
    "        row = pd.Series()\n",
    "        row[\"complete_article\"] = article\n",
    "        row[\"location\"] = [(event['Location'], event['Location'])]\n",
    "        row[\"diseases\"] = event['Disease']\n",
    "        row[\"lang\"] = 'en'\n",
    "        events_list = noevent_ext_obj.perform_noevent_extraction_per_article(row, case_or_death)\n",
    "        if len(events_list) > 1:\n",
    "                print('More than one event:', events_list)\n",
    "        \n",
    "        if len(events_list) == 1:\n",
    "            correct += 1\n",
    "            \n",
    "        total += 1\n",
    "        \n",
    "# Print results\n",
    "print('Total Numberless Events:', total)\n",
    "print('Correct:', correct)\n",
    "print('Accuracy:', correct/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_output_each_phase.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "orig_df = pd.read_csv('final_output_each_phase.csv')\n",
    "df = orig_df.copy()\n",
    "\n",
    "# Preprocess data\n",
    "def rename_keys(d):\n",
    "    return {'incident' if k == 'Incident (case or death)' else 'incident_type' if k == 'Incident Type (new or total)' else k: v for k, v in d.items()}\n",
    "\n",
    "def lower_case_keys(d):\n",
    "    return {k.lower(): v.lower() if isinstance(v, str) else v for k, v in d.items()}\n",
    "\n",
    "df['GT_Events'] = df['GT_Events'].apply(eval)\n",
    "df['events'] = df['events'].apply(eval)\n",
    "df['noevents_events'] = df['noevents_events'].apply(eval)\n",
    "\n",
    "df['GT_Events'] = df['GT_Events'].apply(lambda x: [rename_keys(i) for i in x])\n",
    "df['GT_Events'] = df['GT_Events'].apply(lambda x: [lower_case_keys(i) for i in x])\n",
    "df['events'] = df['events'].apply(lambda x: [lower_case_keys(i) for i in x])\n",
    "\n",
    "\n",
    "df['disease_by_keyword_spotting'] = df['disease_by_keyword_spotting'].apply(lambda x: ', '.join([i.lower() for i in eval(x)]))\n",
    "df['disease_by_ner'] = df['disease_by_ner'].apply(lambda x: ', '.join([i.lower() for i in eval(x)]))\n",
    "\n",
    "# remove rows with no events\n",
    "df = df[df['GT_Events'].apply(len) > 0]\n",
    "\n",
    "print('Total Articles:', df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class EventEvaluation:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.synonyms = json.load(open(\"/home/ubuntu/devesh/Prod_change_12th_jan/idsp_5th_feb/idsp-score/data/05_model_input/disease_synonyms.json\"))\n",
    "\n",
    "    def group_diseases(self, events):\n",
    "        new_events = []\n",
    "        for event in events:\n",
    "            disease = event[\"disease\"]\n",
    "            flag = 0\n",
    "            for key in self.synonyms.keys():\n",
    "                synonyms_for_disease = [x.lower() for x in self.synonyms[key]]\n",
    "                if disease.lower().lstrip().rstrip() in synonyms_for_disease:\n",
    "                    event[\"disease\"] = key.lower()\n",
    "                    event[\"original_disease\"] = disease\n",
    "                    flag = 1\n",
    "                    break  \n",
    "            if flag == 0:\n",
    "                event[\"disease\"] = disease\n",
    "                event[\"original_disease\"] = disease\n",
    "                \n",
    "            new_events.append(event)\n",
    "        return new_events\n",
    "\n",
    "    def precision_recall_method_1(self, pred, gt):\n",
    "        gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "        pred = set(tuple(sorted(d.items())) for d in pred)\n",
    "        \n",
    "        tp = len(pred.intersection(gt))\n",
    "        fp = len(pred.difference(gt))\n",
    "        fn = len(gt.difference(pred))\n",
    "        \n",
    "    \n",
    "        if tp == 0 and fp == 0 and fn == 0:\n",
    "            precision = 1.0; recall = 1.0; f1 = 1.0\n",
    "        elif tp == 0 and (fp > 0 or fn > 0):\n",
    "            precision = 0.0; recall = 0.0; f1 = 0.0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        exact_match = 1.0 if pred == gt else 0.0\n",
    "        \n",
    "        return precision, recall, f1, exact_match\n",
    "    \n",
    "    def precision_recall_method_2(self, pred, gt):\n",
    "        if len(pred) and isinstance(pred[0], dict):\n",
    "            gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "            pred = set(tuple(sorted(d.items())) for d in pred)\n",
    "        elif isinstance(pred, list):\n",
    "            # hand list of list of strings, d.items won't work here\n",
    "            gt = set(gt)\n",
    "            pred = set(pred)\n",
    "            \n",
    "        print(pred, gt)\n",
    "        tp = len(pred.intersection(gt))\n",
    "        fp = len(pred.difference(gt))\n",
    "        fn = len(gt.difference(pred))\n",
    "            \n",
    "        if tp == 0 and fp == 0 and fn == 0:\n",
    "            precision = 1.0; recall = 1.0; f1 = 1.0\n",
    "        elif tp == 0 and (fp > 0 or fn > 0):\n",
    "            precision = 0.0; recall = 0.0; f1 = 0.0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        exact_match = 1.0 if pred == gt else 0.0\n",
    "        \n",
    "        return precision, recall, f1, exact_match\n",
    "\n",
    "    def jaccard_index(self, pred, gt):\n",
    "        # intersection over union\n",
    "        gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "        pred = set(tuple(sorted(d.items())) for d in pred)\n",
    "        if len(pred) == 0 and len(gt) == 0: return 1\n",
    "        intersection = len(pred.intersection(gt))\n",
    "        union = len(pred.union(gt))\n",
    "        return intersection / union\n",
    "    \n",
    "\n",
    "    def subset_accuracy(self, pred, gt):\n",
    "        gt = set(tuple(sorted(d.items())) for d in gt)\n",
    "        pred = set(tuple(sorted(d.items())) for d in pred)\n",
    "        return float(pred.issubset(gt))\n",
    "\n",
    "    def evaluate_event_extraction(self):\n",
    "        # Group diseases using synonyms list\n",
    "        self.df['GT_Events'] = self.df['GT_Events'].apply(lambda events: self.group_diseases(events))\n",
    "        self.df['events'] = self.df['events'].apply(lambda events: self.group_diseases(events))\n",
    "        \n",
    "        # keep only keys disease, location, incident, incident_type, number for comparison\n",
    "\n",
    "        def keys_to_keep(d):\n",
    "            return {k: v for k, v in d.items() if k in ['disease', 'location', 'incident', 'incident_type', 'number']}\n",
    "        self.df['GT_Events'] = self.df['GT_Events'].apply(lambda x: [keys_to_keep(i) for i in x])\n",
    "        self.df['events'] = self.df['events'].apply(lambda x: [keys_to_keep(i) for i in x])\n",
    "        \n",
    "        # apply precision_recall_method_2 to each row\n",
    "        self.df['precision'], self.df['recall'], self.df['f1'], self.df['exact_match'] = zip(*self.df.apply(lambda row: self.precision_recall_method_2(row['events'], row['GT_Events']), axis=1))\n",
    "        self.df['jaccard'] = self.df.apply(lambda row: self.jaccard_index(row['events'], row['GT_Events']), axis=1)\n",
    "        self.df['subset'] = self.df.apply(lambda row: self.subset_accuracy(row['events'], row['GT_Events']), axis=1)\n",
    "        \n",
    "        metrics = {\n",
    "            \"precision\": self.df['precision'].mean(),\n",
    "            \"recall\": self.df['recall'].mean(),\n",
    "            \"f1\": self.df['f1'].mean(),\n",
    "            \"exact_match\": self.df['exact_match'].mean(),\n",
    "            \"jaccard\": self.df['jaccard'].mean(),\n",
    "            \"subset\": self.df['subset'].mean()\n",
    "        }\n",
    "        \n",
    "        return metrics     \n",
    "\n",
    "    def evaluate_relevancy(self):\n",
    "        print('Total number of articles:', len(self.df))\n",
    "        self.df['gt'] = self.df['GT_Events'].apply(lambda x: 1 if len(x) > 0 else 0)\n",
    "        tp = sum((self.df['gt'] == 1) & (self.df['relevant'] == 1))\n",
    "        fp = sum((self.df['gt'] == 0) & (self.df['relevant'] == 1))\n",
    "        fn = sum((self.df['gt'] == 1) & (self.df['relevant'] == 0))\n",
    "        tn = sum((self.df['gt'] == 0) & (self.df['relevant'] == 0))\n",
    "        \n",
    "        \n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        accuracy = (tp + tn)/(tp + fp + tn + fn)\n",
    "        \n",
    "        return precision, recall, f1, accuracy\n",
    "  \n",
    "    def get_disease_ner_metrics(self, gt, pred):\n",
    "        gt = [[i.lower() for i in x] for x in gt]\n",
    "        pred = [[i.lower() for i in x] for x in pred]\n",
    "        precision_list = []; recall_list = []; f1_list = []\n",
    "        for i in range(len(gt)):\n",
    "            tp = 0; fp = 0; fn = 0\n",
    "            \n",
    "            gt_set = set(gt[i])\n",
    "            pred_set = set(pred[i])\n",
    "            \n",
    "            # print(gt_set, pred_set)\n",
    "            \n",
    "            tp += len(gt_set.intersection(pred_set))\n",
    "            fp += len(pred_set.difference(gt_set))\n",
    "            fn += len(gt_set.difference(pred_set))\n",
    "            \n",
    "            if tp == 0 and fp == 0 and fn == 0:\n",
    "                precision = 1\n",
    "                recall = 1\n",
    "                f1 = 0\n",
    "            elif tp == 0 and (fp != 0 or fn != 0):\n",
    "                precision = 0\n",
    "                recall = 0\n",
    "                f1 = 0\n",
    "            else:\n",
    "                precision = tp / (tp + fp)\n",
    "                recall = tp / (tp + fn)\n",
    "                f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            \n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            f1_list.append(f1)\n",
    "            \n",
    "        precision = sum(precision_list) / len(precision_list)\n",
    "        recall = sum(recall_list) / len(recall_list)\n",
    "        f1 = sum(f1_list) / len(f1_list)\n",
    "        \n",
    "        return precision, recall, f1\n",
    "  \n",
    "    \n",
    "    def evaluate_disease_ner(self):\n",
    "        \n",
    "        metrics = {}\n",
    "        new_df = self.df.copy()\n",
    "        # remove rows where 'GT_Events is empty\n",
    "        new_df = new_df[new_df['GT_Events'].apply(len) > 0]\n",
    "        new_df['GT_Events'] = new_df['GT_Events'].apply(lambda events: event_eval.group_diseases(events))\n",
    "\n",
    "        new_df['diseases_gt'] = [[event['disease'] for event in events] for events in new_df['GT_Events']]\n",
    "        new_df = new_df.reset_index(drop=True)\n",
    "   \n",
    "        disease_pred = new_df['disease_by_keyword_spotting'].fillna('').apply(lambda x: x.split(', '))\n",
    "        \n",
    "        new_disease_pred = []\n",
    "        for disease_list in disease_pred:\n",
    "            grouped_disease_list = []\n",
    "            for disease in disease_list:\n",
    "                flag = 0\n",
    "                for key in self.synonyms.keys():\n",
    "                    synonyms_for_disease = [x.lower() for x in self.synonyms[key]]\n",
    "                    if disease.lower().lstrip().rstrip() in synonyms_for_disease:\n",
    "                        grouped_disease_list.append(key)\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    grouped_disease_list.append(disease)\n",
    "                    \n",
    "            new_disease_pred.append(grouped_disease_list)\n",
    "        \n",
    "                    \n",
    "        precision, recall, f1 = self.get_disease_ner_metrics(new_df['diseases_gt'], new_disease_pred)\n",
    "        metrics['disease_by_keyword_spotting'] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "        \n",
    "        disease_pred = new_df['disease_by_ner'].fillna('').apply(lambda x: x.split(', '))\n",
    "        \n",
    "        new_disease_pred = []\n",
    "        for disease_list in disease_pred:\n",
    "            grouped_disease_list = []\n",
    "            for disease in disease_list:\n",
    "                flag = 0\n",
    "                for key in self.synonyms.keys():\n",
    "                    synonyms_for_disease = [x.lower() for x in self.synonyms[key]]\n",
    "                    if disease.lower().lstrip().rstrip() in synonyms_for_disease:\n",
    "                        grouped_disease_list.append(key)\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    grouped_disease_list.append(disease)\n",
    "                    \n",
    "            new_disease_pred.append(grouped_disease_list)\n",
    "            \n",
    "        \n",
    "        precision, recall, f1 = self.get_disease_ner_metrics(new_df['diseases_gt'], new_disease_pred)\n",
    "        metrics['disease_by_ner'] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "        \n",
    "        \n",
    "        disease_pred = new_df['disease_pred'].fillna('').apply(lambda x: x.split(', '))\n",
    "        \n",
    "        new_disease_pred = []\n",
    "        for disease_list in disease_pred:\n",
    "            grouped_disease_list = []\n",
    "            for disease in disease_list:\n",
    "                flag = 0\n",
    "                for key in self.synonyms.keys():\n",
    "                    synonyms_for_disease = [x.lower() for x in self.synonyms[key]]\n",
    "                    if disease.lower().lstrip().rstrip() in synonyms_for_disease:\n",
    "                        grouped_disease_list.append(key)\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    grouped_disease_list.append(disease)\n",
    "            new_disease_pred.append(grouped_disease_list)\n",
    "\n",
    "        precision, recall, f1 = self.get_disease_ner_metrics(new_df['diseases_gt'], new_disease_pred)\n",
    "        metrics['diseases'] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "        \n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def location_ner_metrics(self, predictions, ground_truth):\n",
    "            tp = 0; fp = 0; fn = 0\n",
    "            ground_truth_set = list(set([i['location'].lower() for i in ground_truth]))\n",
    "\n",
    "            for pred_text, pred_entity in predictions:\n",
    "                pred_text = pred_text.lower()\n",
    "                pred_entity = pred_entity.lower()\n",
    "\n",
    "                if pred_text in ground_truth_set or pred_entity in ground_truth_set:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "\n",
    "            fn = len(ground_truth_set) - tp\n",
    "\n",
    "            if tp == 0 and fp == 0 and fn == 0:\n",
    "                precision = 1; recall = 1; f1 = 1\n",
    "            elif tp == 0 and (fp != 0 or fn != 0):\n",
    "                precision = 0; recall = 0; f1 = 0\n",
    "            else:\n",
    "                precision = tp / (tp + fp)\n",
    "                recall = tp / (tp + fn)\n",
    "                f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "            return precision, recall, f1\n",
    "        \n",
    "    def evaluate_location_ner(self):   \n",
    "        \n",
    "        df['precision'], df['recall'], df['f1'] = zip(*df.apply(\n",
    "            lambda row: self.location_ner_metrics(eval(row['locations_pred']), row['GT_Events']),\n",
    "            axis=1\n",
    "        ))\n",
    "\n",
    "        avg_precision = df['precision'].mean()\n",
    "        avg_recall = df['recall'].mean()\n",
    "        avg_f1 = df['f1'].mean()\n",
    "        \n",
    "        return {'precision': avg_precision, 'recall': avg_recall, 'f1': avg_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_eval = EventEvaluation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevancy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, acc, f1,  = event_eval.evaluate_relevancy()\n",
    "print('Relevancy Classifier:')\n",
    "print('Precision:', precision, 'Recall:', recall, 'Accuracy:', acc, 'F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = event_eval.evaluate_disease_ner()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = event_eval.evaluate_location_ner()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "qa_results = {}\n",
    "df = df[df['GT_Events'].apply(len) > 0]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    df_copy = df.copy()\n",
    "    df_copy['events'] = df_copy.apply(lambda x: [i for i in x['events'] if i['score']>=threshold], axis=1)    \n",
    "    event_eval = EventEvaluation(df_copy.copy())\n",
    "    metrics = event_eval.evaluate_event_extraction()\n",
    "    qa_results[threshold] = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to csv\n",
    "import csv\n",
    "fieldnames = ['threshold', 'precision', 'recall', 'f1', 'exact_match', 'jaccard', 'subset']\n",
    "\n",
    "# Write data to CSV file\n",
    "with open('results_each_phase_qa.csv', mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write rows\n",
    "    for threshold, scores in qa_results.items():\n",
    "        row = {'threshold': threshold}\n",
    "        for key, value in scores.items():\n",
    "            row[key] = round(value, 3) \n",
    "        writer.writerow(row)\n",
    "out = pd.read_csv('results_each_phase_qa.csv')\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_events(row): # keep only those rows where number is ''\n",
    "    filtered_events = []\n",
    "    for event in row['GT_Events']:\n",
    "        if event.get('number') == '':\n",
    "            filtered_events.append(event)\n",
    "    row['GT_Events'] = filtered_events\n",
    "    return row\n",
    "\n",
    "nli_results = {}\n",
    "nli_df = df.copy()\n",
    "nli_df = nli_df.apply(filter_events, axis=1)\n",
    "nli_df = nli_df[nli_df['GT_Events'].apply(len) > 0]\n",
    "\n",
    "print('Total number of numberless events in GT: ', sum(nli_df['GT_Events'].apply(len)))\n",
    "print('Total number of articles:', len(nli_df))\n",
    "nli_df['noevents_events'] = nli_df.apply(lambda x: [{**i, 'number': '', 'incident_type': ''} for i in x['noevents_events']], axis=1) # add number and incident_type to each event\n",
    "\n",
    "for threshold in thresholds:\n",
    "    nli_df['events'] = None\n",
    "    nli_df['events'] = nli_df.apply(lambda x: [i for i in x['noevents_events'] if 'score' in i and i['score'] >= threshold], axis=1)\n",
    "    event_eval = EventEvaluation(nli_df)\n",
    "    metrics = event_eval.evaluate_event_extraction()\n",
    "    nli_results[threshold] = metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to csv\n",
    "import csv\n",
    "fieldnames = ['threshold', 'precision', 'recall', 'f1', 'exact_match', 'jaccard', 'subset']\n",
    "\n",
    "# Write data to CSV file\n",
    "with open('results_each_phase_nli.csv', mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write rows\n",
    "    for threshold, scores in nli_results.items():\n",
    "        row = {'threshold': threshold}\n",
    "        for key, value in scores.items():\n",
    "            row[key] = round(value, 3) \n",
    "        writer.writerow(row)\n",
    "out = pd.read_csv('results_each_phase_nli.csv')\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Phase wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"llm_output.csv\")\n",
    "print(df.columns)\n",
    "# Preprocess data\n",
    "\n",
    "def postprocess_number(x):\n",
    "    try:\n",
    "        if type(x) == int:\n",
    "            return x\n",
    "        number = w2n.word_to_num(x)\n",
    "    except:\n",
    "        number = ''\n",
    "        \n",
    "    return number\n",
    "        \n",
    "    \n",
    "def rename_keys(d):\n",
    "    return {'incident' if k == 'Incident (case or death)' else 'incident_type' if k == 'Incident Type (new or total)' else k: v for k, v in d.items()}\n",
    "\n",
    "def lower_case_keys(d):\n",
    "    return {k.lower(): v.lower() if isinstance(v, str) else v for k, v in d.items()}\n",
    "\n",
    "\n",
    "# Convert string to list\n",
    "df['events'] = df['filtered_gpt-3.5-turbo_events']\n",
    "# convert N/A to empty list\n",
    "df['events'] = df['events'].apply(lambda x: '[]' if pd.isna(x) else x)\n",
    "df['events'] = df['events'].apply(eval)\n",
    "\n",
    "\n",
    "# count total no of non empty events\n",
    "print('Total no of non empty events:', df['events'].apply(len).sum())\n",
    "\n",
    "df['GT_Events'] = df['GT_Events'].apply(eval)\n",
    "print('Total no of non empty GT events:', df['GT_Events'].apply(len).sum())\n",
    "\n",
    "# remove articles with no events\n",
    "# df = df[df['GT_Events'].apply(len) > 0]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print('Total Articles:', df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_eval = EventEvaluation(df)\n",
    "# remove rows where 'GT_Events is empty\n",
    "new_df = df[df['GT_Events'].apply(len) > 0]\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "new_df['GT_Events'] = new_df['GT_Events'].apply(lambda events: event_eval.group_diseases(events))\n",
    "new_df['diseases_gt'] = [[event['Disease'] for event in events] for events in new_df['GT_Events']]\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "# in new_df['events'] rename 'disease' key to 'Disease'\n",
    "def rename_keys(d):\n",
    "    return {'Disease' if k == 'disease' else k: v for k, v in d.items()}\n",
    "new_df['events'] = new_df['events'].apply(lambda x: [rename_keys(i) for i in x])\n",
    "new_df['events'] = new_df['events'].apply(lambda events: event_eval.group_diseases(events))\n",
    "new_df['diseases_pred'] = new_df['events'].apply(lambda x: [i['Disease'] for i in x])\n",
    "# rename 'disease' key to 'Disease' \n",
    "print(new_df['diseases_pred'][:5])\n",
    "disease_pred = new_df['diseases_pred']\n",
    "precision, recall, f1 = event_eval.get_disease_ner_metrics(new_df['diseases_gt'], disease_pred)\n",
    "print('Disease NER:')\n",
    "print('Precision:', precision, 'Recall:', recall, 'F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(394, 12)\n",
      "['Gwalior', 'Gwalior', 'Gwalior'] ['Gwalior', 'Gwalior']\n",
      "{'Gwalior'} {'Gwalior'}\n",
      "[] ['Uttarakhand', 'Uttarkhand']\n",
      "set() {'Uttarkhand', 'Uttarakhand'}\n",
      "['Ambikapur'] ['Ambikapur']\n",
      "{'Ambikapur'} {'Ambikapur'}\n",
      "['Bilaspur'] ['Bilashpur']\n",
      "{'Bilaspur'} {'Bilashpur'}\n",
      "['India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Nagpur'] ['Nagpur']\n",
      "{'Nagpur'} {'Nagpur'}\n",
      "['Karnal'] ['Karnal', 'Karnal']\n",
      "{'Karnal'} {'Karnal'}\n",
      "['Chhattisgarh'] ['Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "[] ['Nagaur']\n",
      "set() {'Nagaur'}\n",
      "['Delhi', 'Delhi', 'Delhi'] ['Delhi', 'Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['Delhi', 'Delhi'] ['Delhi', 'Delhi', 'Delhi ']\n",
      "{'Delhi'} {'Delhi ', 'Delhi'}\n",
      "['Kaithal'] ['India']\n",
      "{'Kaithal'} {'India'}\n",
      "['Kaithal'] ['']\n",
      "{'Kaithal'} {''}\n",
      "['Muzaffarpur', 'Muzaffarpur', 'Muzaffarpur', 'Muzaffarpur'] ['Bihar']\n",
      "{'Muzaffarpur'} {'Bihar'}\n",
      "['Muzaffarpur', 'Muzaffarpur', 'Muzaffarpur', 'Muzaffarpur'] ['Muzaffarpur', 'Muzaffarpur', 'Muzaffarpur', 'Muzzaffarpur']\n",
      "{'Muzaffarpur'} {'Muzzaffarpur', 'Muzaffarpur'}\n",
      "['Rewari'] ['Rewari']\n",
      "{'Rewari'} {'Rewari'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Kanpur', 'Kanpur'] ['Kanpur', 'Kanpur']\n",
      "{'Kanpur'} {'Kanpur'}\n",
      "['Pune', 'Pune'] ['Pune', 'Pune ', 'Pune']\n",
      "{'Pune'} {'Pune', 'Pune '}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Jaipur', 'Jaipur'] ['Rajasthan', 'Rajasthan']\n",
      "{'Jaipur'} {'Rajasthan'}\n",
      "['Raipur', 'Raipur', 'Chhattisgarh'] ['Chattisgarh', 'Chattisgarh', 'Chhattisgarh', '']\n",
      "{'Chhattisgarh', 'Raipur'} {'', 'Chattisgarh', 'Chhattisgarh'}\n",
      "[] ['Ratia']\n",
      "set() {'Ratia'}\n",
      "['Lucknow'] ['Lucknow', 'Lucknow', 'Lucknow', 'Lucknow', 'Lucknow', 'Lucknow']\n",
      "{'Lucknow'} {'Lucknow'}\n",
      "['India', 'Kerala'] ['India', 'Kerala']\n",
      "{'India', 'Kerala'} {'India', 'Kerala'}\n",
      "[] ['Firozabad']\n",
      "set() {'Firozabad'}\n",
      "['Panchkula', 'Panchkula'] ['', '']\n",
      "{'Panchkula'} {''}\n",
      "['Delhi', 'Maharashtra', 'Chhattisgarh', 'Delhi', 'Gujarat', 'Haryana', 'Karnataka', 'Puducherry', 'Rajasthan', 'India'] ['India', 'India', 'Chhattisgarh', 'Delhi', 'Gujarat', 'Haryana', 'Karnataka', 'Puducherry', 'Rajasthan', 'Maharashtra']\n",
      "{'India', 'Haryana', 'Gujarat', 'Chhattisgarh', 'Puducherry', 'Rajasthan', 'Maharashtra', 'Karnataka', 'Delhi'} {'India', 'Haryana', 'Gujarat', 'Chhattisgarh', 'Puducherry', 'Rajasthan', 'Maharashtra', 'Karnataka', 'Delhi'}\n",
      "['Madhya Pradesh'] ['Madhya Pradesh']\n",
      "{'Madhya Pradesh'} {'Madhya Pradesh'}\n",
      "['Madhya Pradesh', 'Bhopal', 'Gwalior'] ['Madhya Pradesh', 'Bhopal', 'Gwalior']\n",
      "{'Madhya Pradesh', 'Bhopal', 'Gwalior'} {'Madhya Pradesh', 'Bhopal', 'Gwalior'}\n",
      "['Gwalior'] ['Gwalior']\n",
      "{'Gwalior'} {'Gwalior'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Gwalior'] ['Gwalior']\n",
      "{'Gwalior'} {'Gwalior'}\n",
      "['Kolkata Airport', 'India'] ['Kolkata', 'UP', 'Bihar', 'India']\n",
      "{'India', 'Kolkata Airport'} {'UP', 'Bihar', 'Kolkata', 'India'}\n",
      "['Hisar'] ['Hisar']\n",
      "{'Hisar'} {'Hisar'}\n",
      "['Hisar'] ['Hisar']\n",
      "{'Hisar'} {'Hisar'}\n",
      "['Uttar Pradesh', 'Uttar Pradesh', 'Lucknow', 'Prayagraj', 'Ayodhya'] ['Uttar Pradesh', 'Uttar Pradesh', 'Lucknow', 'Prayagraj', 'Ayodhya']\n",
      "{'Prayagraj', 'Ayodhya', 'Uttar Pradesh', 'Lucknow'} {'Prayagraj', 'Ayodhya', 'Uttar Pradesh', 'Lucknow'}\n",
      "['Uttar Pradesh', 'Uttar Pradesh', 'Lucknow', 'Prayagraj', 'Ayodhya'] ['Uttar Pradesh', 'Uttar Pradesh', 'Lucknow', 'Prayagraj', 'Ayodhya']\n",
      "{'Prayagraj', 'Ayodhya', 'Uttar Pradesh', 'Lucknow'} {'Prayagraj', 'Ayodhya', 'Uttar Pradesh', 'Lucknow'}\n",
      "['Ghaziabad', 'Ghaziabad'] ['Ghaziabad']\n",
      "{'Ghaziabad'} {'Ghaziabad'}\n",
      "['Ghaziabad', 'Ghaziabad'] ['Ghaziabad']\n",
      "{'Ghaziabad'} {'Ghaziabad'}\n",
      "['Meerut'] ['Meerut']\n",
      "{'Meerut'} {'Meerut'}\n",
      "['Meerut', 'Meerut Cantt', 'Rajban'] ['Meerut', 'Meerut Cantt', 'Rajban']\n",
      "{'Rajban', 'Meerut', 'Meerut Cantt'} {'Rajban', 'Meerut', 'Meerut Cantt'}\n",
      "['India', 'India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['New Delhi', 'New Delhi', 'New Delhi'] ['India', 'India', 'Thane']\n",
      "{'New Delhi'} {'India', 'Thane'}\n",
      "[] ['Bilaspur', 'Jashpur', 'Bilaspur']\n",
      "set() {'Jashpur', 'Bilaspur'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Bilaspur', 'Jashpur'] ['Bilaspur ', 'Jashpur']\n",
      "{'Jashpur', 'Bilaspur'} {'Bilaspur ', 'Jashpur'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Chhattisgarh'] ['Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Agra'] ['Agra']\n",
      "{'Agra'} {'Agra'}\n",
      "['Kerala', 'Kerala', 'Kerala'] ['Kerela', 'Kerela', 'Kerela', 'Kerela']\n",
      "{'Kerala'} {'Kerela'}\n",
      "['Ghaziabad'] ['Ghaziabad']\n",
      "{'Ghaziabad'} {'Ghaziabad'}\n",
      "[''] ['']\n",
      "{''} {''}\n",
      "['Hisar', 'Hisar'] ['Haryana', 'Haryana']\n",
      "{'Hisar'} {'Haryana'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Haldwani'] ['Uttarakhand']\n",
      "{'Haldwani'} {'Uttarakhand'}\n",
      "['Panchkula'] ['Panchkula']\n",
      "{'Panchkula'} {'Panchkula'}\n",
      "['Uttar Pradesh'] ['Uttar Pradesh']\n",
      "{'Uttar Pradesh'} {'Uttar Pradesh'}\n",
      "['Madhepura'] ['Madhepura']\n",
      "{'Madhepura'} {'Madhepura'}\n",
      "['Mirzapur'] ['Halia']\n",
      "{'Mirzapur'} {'Halia'}\n",
      "['Raipur', 'Raipur'] ['Raipur', 'Raipur']\n",
      "{'Raipur'} {'Raipur'}\n",
      "['Kolkata', 'Kolkata', 'West Bengal'] ['Kolkata', 'West Bengal']\n",
      "{'West Bengal', 'Kolkata'} {'West Bengal', 'Kolkata'}\n",
      "['New Delhi', 'New Delhi'] ['New Delhi']\n",
      "{'New Delhi'} {'New Delhi'}\n",
      "[] ['Haldwani']\n",
      "set() {'Haldwani'}\n",
      "['Kolkata'] ['Kolkata']\n",
      "{'Kolkata'} {'Kolkata'}\n",
      "['Chhattisgarh', 'Bilaspur', 'Bilaspur', 'Dhamtari'] ['Chhattisgarh', 'Bilaspur', 'Bilaspur', 'Dhamtari', 'Bilaspur']\n",
      "{'Chhattisgarh', 'Bilaspur', 'Dhamtari'} {'Chhattisgarh', 'Bilaspur', 'Dhamtari'}\n",
      "['Noida'] ['Noida']\n",
      "{'Noida'} {'Noida'}\n",
      "['India', 'India'] ['India']\n",
      "{'India'} {'India'}\n",
      "[] ['Uttarkhand']\n",
      "set() {'Uttarkhand'}\n",
      "[] [\"Bihar's Gaya\"]\n",
      "set() {\"Bihar's Gaya\"}\n",
      "['Indore', 'Bhopal', 'Gwalior'] ['Bhopal', 'Indore', 'Gwalior', 'Madhya Pradesh']\n",
      "{'Indore', 'Bhopal', 'Gwalior'} {'Indore', 'Bhopal', 'Madhya Pradesh', 'Gwalior'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Bharatpur'] ['Bharatpur']\n",
      "{'Bharatpur'} {'Bharatpur'}\n",
      "['Hathras'] ['Hathras']\n",
      "{'Hathras'} {'Hathras'}\n",
      "['Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "[] ['India']\n",
      "set() {'India'}\n",
      "['Meerut'] ['Meerut']\n",
      "{'Meerut'} {'Meerut'}\n",
      "[] ['India']\n",
      "set() {'India'}\n",
      "['Deoria'] ['Deoria']\n",
      "{'Deoria'} {'Deoria'}\n",
      "['Banda'] ['Banda']\n",
      "{'Banda'} {'Banda'}\n",
      "['Deoria'] ['Deoria']\n",
      "{'Deoria'} {'Deoria'}\n",
      "['Delhi'] ['Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "[] ['Kota', 'Kota']\n",
      "set() {'Kota'}\n",
      "['Delhi'] ['Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Panipat'] ['Panipat']\n",
      "{'Panipat'} {'Panipat'}\n",
      "['Panipat'] ['Panipat']\n",
      "{'Panipat'} {'Panipat'}\n",
      "['Thane'] ['Ambernath', 'shahapur', 'Bhiwandi']\n",
      "{'Thane'} {'shahapur', 'Ambernath', 'Bhiwandi'}\n",
      "['Aligarh'] ['Aligarh', 'Aligarh']\n",
      "{'Aligarh'} {'Aligarh'}\n",
      "['Delhi', 'Delhi'] ['Delhi', 'Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "[] ['Chandrapur']\n",
      "set() {'Chandrapur'}\n",
      "['Bihar', 'Patna', 'Gaya', 'Purnea', 'Bhagalpur', 'Khagaria'] ['Bihar', 'Patna', 'Gaya', 'Purnea', 'Bhagalpur', 'Khagaria']\n",
      "{'Purnea', 'Patna', 'Bihar', 'Bhagalpur', 'Khagaria', 'Gaya'} {'Purnea', 'Patna', 'Bihar', 'Bhagalpur', 'Khagaria', 'Gaya'}\n",
      "['Gautam Budh Nagar', 'Uttar Pradesh'] ['Gautam Budh Nagar,UP', 'Uttar Pradesh']\n",
      "{'Gautam Budh Nagar', 'Uttar Pradesh'} {'Gautam Budh Nagar,UP', 'Uttar Pradesh'}\n",
      "['Kathua'] ['Kathua']\n",
      "{'Kathua'} {'Kathua'}\n",
      "[] ['Saharanpur']\n",
      "set() {'Saharanpur'}\n",
      "['Panchkula'] ['Panchkula']\n",
      "{'Panchkula'} {'Panchkula'}\n",
      "['Jaipur', 'Jaipur', 'Jaipur'] ['Jaipur', 'Jaipur']\n",
      "{'Jaipur'} {'Jaipur'}\n",
      "['Durg', 'Chhattisgarh', 'Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh']\n",
      "{'Durg', 'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Ambala'] ['Ambala']\n",
      "{'Ambala'} {'Ambala'}\n",
      "['Bihar', 'Agra', 'Bengaluru', 'Kolkata'] ['Bihar', 'India', 'Bengaluru', 'Kolkata']\n",
      "{'Bihar', 'Agra', 'Bengaluru', 'Kolkata'} {'India', 'Bihar', 'Bengaluru', 'Kolkata'}\n",
      "['Bihar Gaya', 'Agra', 'India', 'Bengaluru', 'Kolkata'] ['Agra', 'Bihar', 'Kolkata', 'Bengaluru', 'India']\n",
      "{'India', 'Bihar Gaya', 'Bengaluru', 'Kolkata', 'Agra'} {'India', 'Bihar', 'Bengaluru', 'Kolkata', 'Agra'}\n",
      "['Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra']\n",
      "{'Maharashtra'} {'Maharashtra'}\n",
      "['Bihar', 'Patna'] ['Bihar ', 'Patna']\n",
      "{'Bihar', 'Patna'} {'Patna', 'Bihar '}\n",
      "['Maharashtra', 'Maharashtra'] ['Maharastra', 'Maharastra']\n",
      "{'Maharashtra'} {'Maharastra'}\n",
      "[] ['Uttar Pradesh']\n",
      "set() {'Uttar Pradesh'}\n",
      "['Delhi', 'Ghaziabad', 'Gautam Buddha Nagar', 'Ghaziabad'] ['Delhi', 'Ghaziabad', 'Noida', 'Ghaziabad']\n",
      "{'Delhi', 'Ghaziabad', 'Gautam Buddha Nagar'} {'Noida', 'Delhi', 'Ghaziabad'}\n",
      "['Jaipur', 'Dholpur'] ['Jaipur', 'Dholpur']\n",
      "{'Jaipur', 'Dholpur'} {'Jaipur', 'Dholpur'}\n",
      "['Ahmatia', 'Ahmatia'] ['Ahmatia']\n",
      "{'Ahmatia'} {'Ahmatia'}\n",
      "['Madhya Pradesh'] ['Madhya Pradesh']\n",
      "{'Madhya Pradesh'} {'Madhya Pradesh'}\n",
      "['Bhiwandi', 'Bhiwandi'] ['Bhiwandi']\n",
      "{'Bhiwandi'} {'Bhiwandi'}\n",
      "['Rohtak'] ['Rohtak,Haryana']\n",
      "{'Rohtak'} {'Rohtak,Haryana'}\n",
      "[] ['Maycha', 'Chithehra', 'Maycha', 'Chithehra']\n",
      "set() {'Chithehra', 'Maycha'}\n",
      "['Gujarat', 'Gujarat', 'Gujarat'] ['Gujarat', 'Gujarat', 'Gujarat', 'Gujarat']\n",
      "{'Gujarat'} {'Gujarat'}\n",
      "['New Delhi', 'New Delhi'] ['India', 'India']\n",
      "{'New Delhi'} {'India'}\n",
      "['Raebareli', 'Raebareli'] ['Raebareli', 'Raebareli']\n",
      "{'Raebareli'} {'Raebareli'}\n",
      "[] ['Odisha']\n",
      "set() {'Odisha'}\n",
      "['India', 'India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Jammu and Kashmir', 'Jammu and Kashmir', 'Jammu and Kashmir', 'Jammu and Kashmir', 'Jammu and Kashmir'] ['Jammu and Kashmir', 'Jammu and Kashmir']\n",
      "{'Jammu and Kashmir'} {'Jammu and Kashmir'}\n",
      "['Banda', 'Banda'] ['Banda', 'Banda']\n",
      "{'Banda'} {'Banda'}\n",
      "['Ludhiana'] ['Ludhiana']\n",
      "{'Ludhiana'} {'Ludhiana'}\n",
      "['Hisar', 'Hisar'] ['Hisar', 'Hisar']\n",
      "{'Hisar'} {'Hisar'}\n",
      "['Supaul'] [\"Bihar's Supaul\"]\n",
      "{'Supaul'} {\"Bihar's Supaul\"}\n",
      "['Rajasthan'] ['Rajasthan']\n",
      "{'Rajasthan'} {'Rajasthan'}\n",
      "['Lalitpur Metropolitan City'] ['Kathmandu Valley']\n",
      "{'Lalitpur Metropolitan City'} {'Kathmandu Valley'}\n",
      "['Jharkhand', 'Jharkhand', 'Jharkhand'] ['Jharkhand', 'Jharkhand']\n",
      "{'Jharkhand'} {'Jharkhand'}\n",
      "['Delhi', 'Delhi', 'Delhi'] ['Delhi', 'Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "[] ['Sukma']\n",
      "set() {'Sukma'}\n",
      "['Delhi', 'Kerala', 'Kerala', 'India'] ['India', 'Kerela', 'Delhi', 'Kerela']\n",
      "{'India', 'Kerala', 'Delhi'} {'India', 'Kerela', 'Delhi'}\n",
      "['Chhattisgarh', 'Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Delhi', 'Delhi', 'Delhi'] ['Delhi', 'Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India', 'Maharastra']\n",
      "{'India'} {'India', 'Maharastra'}\n",
      "['Delhi', 'Kerala', 'India'] ['Delhi', 'Kerala', 'Kerala', 'India']\n",
      "{'India', 'Kerala', 'Delhi'} {'India', 'Kerala', 'Delhi'}\n",
      "['Kerala'] ['Kerala']\n",
      "{'Kerala'} {'Kerala'}\n",
      "['Haryana', 'Gurugram'] ['Haryana', 'Gurugram', 'Delhi']\n",
      "{'Haryana', 'Gurugram'} {'Haryana', 'Delhi', 'Gurugram'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['Telangana', 'Gujarat', 'Karnataka', 'Rajasthan'] ['India', 'Telangana', 'Gujarat', 'Karnataka', 'Rajasthan']\n",
      "{'Karnataka', 'Rajasthan', 'Gujarat', 'Telangana'} {'India', 'Gujarat', 'Rajasthan', 'Karnataka', 'Telangana'}\n",
      "['Gujarat'] ['India']\n",
      "{'Gujarat'} {'India'}\n",
      "['Telangana', 'Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['New Delhi'] ['India']\n",
      "{'New Delhi'} {'India'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India'] ['Corona']\n",
      "{'India'} {'Corona'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Delhi'] ['Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['India', 'India', 'India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Telangana', 'Telangana', 'Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India', 'Kerala', 'Maharashtra', 'Delhi', 'Tamil Nadu', 'Gujarat', 'Haryana', 'Karnataka', 'Uttar Pradesh'] ['India', 'India', 'Kerela', 'Maharastra', 'Delhi', 'TamilNadu', 'Gujarat', 'Haryana', 'Karnataka', 'UttarPradesh']\n",
      "{'India', 'Haryana', 'Gujarat', 'Uttar Pradesh', 'Maharashtra', 'Karnataka', 'Kerala', 'Delhi', 'Tamil Nadu'} {'India', 'Haryana', 'Delhi', 'Maharastra', 'Gujarat', 'UttarPradesh', 'TamilNadu', 'Karnataka', 'Kerela'}\n",
      "['Andhra Pradesh', 'Andhra Pradesh'] ['Andhra Pradesh', 'Andhra Pradesh']\n",
      "{'Andhra Pradesh'} {'Andhra Pradesh'}\n",
      "['India', 'India', 'Kerala', 'Maharashtra', 'Delhi', 'Karnataka', 'Haryana'] ['India', 'India', 'Kerela', 'Maharashtra', 'Delhi', 'Karnataka', 'Haryana']\n",
      "{'India', 'Haryana', 'Maharashtra', 'Karnataka', 'Kerala', 'Delhi'} {'India', 'Haryana', 'Delhi', 'Maharashtra', 'Karnataka', 'Kerela'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'Kerala', 'India']\n",
      "{'India'} {'India', 'Kerala'}\n",
      "['Coimbatore'] ['Coimbatore']\n",
      "{'Coimbatore'} {'Coimbatore'}\n",
      "['Delhi', 'Delhi', 'Delhi'] ['Delhi', 'Delhi', 'Delhi', 'Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['Mumbai', 'Mumbai'] ['Mumbai', 'Mumbai ', 'Mumbai']\n",
      "{'Mumbai'} {'Mumbai ', 'Mumbai'}\n",
      "['Maharashtra', 'Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra', 'Maharashtra', 'Maharashtra']\n",
      "{'Maharashtra'} {'Maharashtra'}\n",
      "[] ['Dhanbad']\n",
      "set() {'Dhanbad'}\n",
      "['Gurgaon', 'Gurgaon'] ['Gurgaon']\n",
      "{'Gurgaon'} {'Gurgaon'}\n",
      "['Thane'] ['Thane', 'Thane', 'Thane']\n",
      "{'Thane'} {'Thane'}\n",
      "['Salem', 'Namakkal'] ['Salem', 'Namakkal']\n",
      "{'Namakkal', 'Salem'} {'Namakkal', 'Salem'}\n",
      "['India', 'Kerala', 'Delhi'] ['India', 'India', 'Kerala', 'Delhi', 'India']\n",
      "{'India', 'Kerala', 'Delhi'} {'India', 'Kerala', 'Delhi'}\n",
      "['Chhattisgarh', 'Chhattisgarh'] ['Chhattisgarh', 'Chhattisgarh', 'Chhattisgarh', 'Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Kerala'] ['Kerala', 'Vechur', 'Neendoor', 'Arapukkara']\n",
      "{'Kerala'} {'Vechur', 'Kerala', 'Arapukkara', 'Neendoor'}\n",
      "['Delhi', 'Delhi'] ['Delhi', 'Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['Maharashtra', 'Maharashtra', 'Maharashtra', 'Maharashtra'] ['Maharasthra', 'Maharasthra', 'Maharasthra']\n",
      "{'Maharashtra'} {'Maharasthra'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India', 'Kerala', 'India']\n",
      "{'India'} {'India', 'Kerala'}\n",
      "['Iraq', 'Iraq', 'Iraq'] ['Iraq', 'Iraq']\n",
      "{'Iraq'} {'Iraq'}\n",
      "['India', 'India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Delhi'] ['Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Bihar', 'India'] ['Bihar', 'India']\n",
      "{'India', 'Bihar'} {'India', 'Bihar'}\n",
      "['Maharashtra', 'Maharashtra'] ['Maharashtra', 'Pune']\n",
      "{'Maharashtra'} {'Pune', 'Maharashtra'}\n",
      "['India', 'India', 'Telangana', 'Telangana', 'Telangana'] ['Telangana', 'India']\n",
      "{'India', 'Telangana'} {'India', 'Telangana'}\n",
      "[] ['India']\n",
      "set() {'India'}\n",
      "['Telangana', 'Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['Patiala', 'Patiala'] ['Patiala']\n",
      "{'Patiala'} {'Patiala'}\n",
      "[] ['Gujarat', 'Odisha', 'China', '']\n",
      "set() {'', 'Gujarat', 'Odisha', 'China'}\n",
      "['Gujarat'] ['Gujarat', 'Gujarat']\n",
      "{'Gujarat'} {'Gujarat'}\n",
      "['Rajasthan'] ['Rajasthan']\n",
      "{'Rajasthan'} {'Rajasthan'}\n",
      "[] ['India', 'Gujarat', 'Odisha', 'China']\n",
      "set() {'India', 'Gujarat', 'Odisha', 'China'}\n",
      "['Gujarat'] ['Gujarat', 'Gujarat']\n",
      "{'Gujarat'} {'Gujarat'}\n",
      "['Mumbai', 'Mumbai', 'Mumbai'] ['Mumbai', 'Mumbai', 'Mumbai']\n",
      "{'Mumbai'} {'Mumbai'}\n",
      "['Thane', 'Thane'] ['Thane', 'Thane', 'Thane']\n",
      "{'Thane'} {'Thane'}\n",
      "['Kerala'] ['Kerela']\n",
      "{'Kerala'} {'Kerela'}\n",
      "['Alwar'] ['Alwar,Rajasthan', 'Bahadurgarh']\n",
      "{'Alwar'} {'Bahadurgarh', 'Alwar,Rajasthan'}\n",
      "['Punjab', 'Lahore'] ['Punjab', 'Punjab', 'Punjab']\n",
      "{'Punjab', 'Lahore'} {'Punjab'}\n",
      "['India', 'India', 'India', 'India', 'India', 'India'] ['India', 'India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Assam', 'Nagaon', 'Nalbari', 'Udalguri', 'Sivasagar', 'Barpeta', 'Kamrup (Metro)', 'Karbi Anglong East', 'Hojai'] ['', 'Nalbari', 'Nagaon', 'Udalguri', 'Sivasagar', 'Barpeta', 'Kamrup', 'Karbi Anglong East', 'Hojai district']\n",
      "{'Sivasagar', 'Udalguri', 'Karbi Anglong East', 'Hojai', 'Nagaon', 'Barpeta', 'Kamrup (Metro)', 'Assam', 'Nalbari'} {'', 'Kamrup', 'Hojai district', 'Sivasagar', 'Udalguri', 'Karbi Anglong East', 'Nagaon', 'Barpeta', 'Nalbari'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Patiala', 'Patiala'] ['Patiala', 'Patiala']\n",
      "{'Patiala'} {'Patiala'}\n",
      "['Punjab'] ['Punjab']\n",
      "{'Punjab'} {'Punjab'}\n",
      "[] ['Rajasthan']\n",
      "set() {'Rajasthan'}\n",
      "['Jammu and Kashmir'] ['Jammu and Kashmir', 'Jammu and Kashmir']\n",
      "{'Jammu and Kashmir'} {'Jammu and Kashmir'}\n",
      "['Amritsar'] ['Amritsar']\n",
      "{'Amritsar'} {'Amritsar'}\n",
      "['Lucknow', 'Lucknow'] ['Lucknow', 'Lucknow']\n",
      "{'Lucknow'} {'Lucknow'}\n",
      "['Malappuram'] ['Malapurram']\n",
      "{'Malappuram'} {'Malapurram'}\n",
      "['Chennai'] ['T.N']\n",
      "{'Chennai'} {'T.N'}\n",
      "['Gurgaon', 'Gurgaon'] ['Gurgaon']\n",
      "{'Gurgaon'} {'Gurgaon'}\n",
      "['Thane'] ['Thane', 'Thane']\n",
      "{'Thane'} {'Thane'}\n",
      "['India', 'India', 'India', 'India'] ['India', 'India', 'India', 'Kerala']\n",
      "{'India'} {'India', 'Kerala'}\n",
      "['Karnataka', 'Karnataka'] ['Karnataka', 'Karnataka', 'Bengaluru']\n",
      "{'Karnataka'} {'Karnataka', 'Bengaluru'}\n",
      "['Wayanad'] ['Kerela']\n",
      "{'Wayanad'} {'Kerela'}\n",
      "['Kakkanad, Ernakulam, Kerala'] ['Kerela']\n",
      "{'Kakkanad, Ernakulam, Kerala'} {'Kerela'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India', 'India', 'Kerala'] ['India', 'India', 'India']\n",
      "{'India', 'Kerala'} {'India'}\n",
      "['Guinea'] ['Guinea', 'Guinea', 'Guinea', 'Gueckedou']\n",
      "{'Guinea'} {'Guinea', 'Gueckedou'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['Karnataka', 'Bruhat Bengaluru Mahanagara Palike'] ['Karnataka', 'Bengaluru', 'Mahadevapura zone', 'RR Nagar zone']\n",
      "{'Karnataka', 'Bruhat Bengaluru Mahanagara Palike'} {'Karnataka', 'RR Nagar zone', 'Mahadevapura zone', 'Bengaluru'}\n",
      "['Gujarat'] ['Gujarat']\n",
      "{'Gujarat'} {'Gujarat'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Jammu and Kashmir', 'Jammu and Kashmir'] ['Jammu and Kashmir', 'Jammu and Kashmir', 'Jammu and Kashmir', 'Jammu and Kashmir', 'Jammu division', 'Kashmir Valley']\n",
      "{'Jammu and Kashmir'} {'Kashmir Valley', 'Jammu division', 'Jammu and Kashmir'}\n",
      "['Jammu and Kashmir'] ['J-K', 'J-K']\n",
      "{'Jammu and Kashmir'} {'J-K'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Siliguri'] ['Siliguri']\n",
      "{'Siliguri'} {'Siliguri'}\n",
      "['Gurgaon', 'Gurgaon'] ['Gurgaon ', 'Gurgaon']\n",
      "{'Gurgaon'} {'Gurgaon', 'Gurgaon '}\n",
      "['India', 'India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "[] ['Ballia District', 'Ballia District ', 'Ballia District', 'Ballia District']\n",
      "set() {'Ballia District', 'Ballia District '}\n",
      "['Rajasthan', 'Jhalawar', 'Bikaner'] ['Rajasthan', 'Jhalawar', 'Bikaner']\n",
      "{'Bikaner', 'Rajasthan', 'Jhalawar'} {'Bikaner', 'Rajasthan', 'Jhalawar'}\n",
      "['Ludhiana'] ['Ludhiana', 'Ludhiana']\n",
      "{'Ludhiana'} {'Ludhiana'}\n",
      "['Mysuru', 'Mysuru'] ['Mysuru', 'Mysuru']\n",
      "{'Mysuru'} {'Mysuru'}\n",
      "['Telangana', 'Telangana'] ['Telengana']\n",
      "{'Telangana'} {'Telengana'}\n",
      "['Rajkot', 'Rajkot'] ['Rajkot', 'Rajkot ']\n",
      "{'Rajkot'} {'Rajkot', 'Rajkot '}\n",
      "['Delhi', 'Delhi', 'Maharashtra'] ['Delhi', 'Delhi', 'Maharashtra']\n",
      "{'Delhi', 'Maharashtra'} {'Delhi', 'Maharashtra'}\n",
      "['Madhya Pradesh'] ['Madhya Pradesh', 'Madhya Pradesh', 'Madhya Pradesh', 'Madhya Pradesh']\n",
      "{'Madhya Pradesh'} {'Madhya Pradesh'}\n",
      "['Coimbatore'] ['Coimbatore']\n",
      "{'Coimbatore'} {'Coimbatore'}\n",
      "['India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Ahmedabad', 'Ahmedabad'] ['Ahmedabad']\n",
      "{'Ahmedabad'} {'Ahmedabad'}\n",
      "['Arunachal Pradesh'] ['Arunachal Pradesh', 'Arunachal Pradesh']\n",
      "{'Arunachal Pradesh'} {'Arunachal Pradesh'}\n",
      "['Gujarat', 'Gir Somnath'] ['Gujarat ', 'Ahmedabad', 'Vadodara', 'Mehsana', 'Surat', 'Rajkot', 'Gir Somanth']\n",
      "{'Gujarat', 'Gir Somnath'} {'Vadodara', 'Mehsana', 'Rajkot', 'Gir Somanth', 'Gujarat ', 'Surat', 'Ahmedabad'}\n",
      "['Tamil Nadu'] ['IIT Madras', 'Tamil Nadu ']\n",
      "{'Tamil Nadu'} {'IIT Madras', 'Tamil Nadu '}\n",
      "['Chennai'] ['Tamil Nadu']\n",
      "{'Chennai'} {'Tamil Nadu'}\n",
      "['India', 'Maharashtra', 'Kerala'] ['India', 'India ', 'Kerala', 'Maharashtra']\n",
      "{'India', 'Kerala', 'Maharashtra'} {'India', 'Kerala', 'India ', 'Maharashtra'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Haryana', 'Karnataka'] ['India']\n",
      "{'Karnataka', 'Haryana'} {'India'}\n",
      "['India', 'India', 'India', 'India', 'Maharashtra', 'Kerala'] ['India', 'India', 'Maharastra']\n",
      "{'India', 'Kerala', 'Maharashtra'} {'India', 'Maharastra'}\n",
      "['India', 'India', 'India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India'] ['India', 'Kerela', 'Delhi']\n",
      "{'India'} {'India', 'Kerela', 'Delhi'}\n",
      "['Delhi'] ['Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['Chhattisgarh'] ['Chhattisgarh']\n",
      "{'Chhattisgarh'} {'Chhattisgarh'}\n",
      "['Lucknow', 'Lucknow'] ['Lucknow', 'Lucknow']\n",
      "{'Lucknow'} {'Lucknow'}\n",
      "[] ['China']\n",
      "set() {'China'}\n",
      "['Odisha'] ['Odisha']\n",
      "{'Odisha'} {'Odisha'}\n",
      "['Thane', 'Thane'] ['Thane', 'Thane', 'Thane']\n",
      "{'Thane'} {'Thane'}\n",
      "[] ['UP Village']\n",
      "set() {'UP Village'}\n",
      "['Mohali'] ['Mohali']\n",
      "{'Mohali'} {'Mohali'}\n",
      "['India', 'India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Punjab', 'Fazilka'] ['', 'Punjab', 'Punjab', 'Fazilka']\n",
      "{'Punjab', 'Fazilka'} {'', 'Punjab', 'Fazilka'}\n",
      "[] ['']\n",
      "set() {''}\n",
      "['Jharkhand', 'Jharkhand'] [\"J'khand\", \"J'khand\"]\n",
      "{'Jharkhand'} {\"J'khand\"}\n",
      "['Mysuru', 'Mysuru'] ['Mysuru', 'Mysuru']\n",
      "{'Mysuru'} {'Mysuru'}\n",
      "['Gujarat', 'Gujarat'] ['Gujarat', 'Gujarat']\n",
      "{'Gujarat'} {'Gujarat'}\n",
      "[] ['Mahabubabad']\n",
      "set() {'Mahabubabad'}\n",
      "['Kasba Tarle'] ['Kasba Tarle']\n",
      "{'Kasba Tarle'} {'Kasba Tarle'}\n",
      "['Maharashtra', 'Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra', 'Maharashtra', 'India']\n",
      "{'Maharashtra'} {'India', 'Maharashtra'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India', 'India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Telangana', 'Hyderabad'] ['Telangana']\n",
      "{'Telangana', 'Hyderabad'} {'Telangana'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Karnataka'] ['Karnataka']\n",
      "{'Karnataka'} {'Karnataka'}\n",
      "['Telangana', 'Hyderabad', 'Rangareddy', 'Medchal'] ['Telangana', 'Hyderabad', 'Rangareddy', 'Medchal']\n",
      "{'Rangareddy', 'Telangana', 'Medchal', 'Hyderabad'} {'Rangareddy', 'Telangana', 'Medchal', 'Hyderabad'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Delhi', 'India'] ['India', 'Delhi']\n",
      "{'India', 'Delhi'} {'India', 'Delhi'}\n",
      "['Kerala'] ['Kerela']\n",
      "{'Kerala'} {'Kerela'}\n",
      "['Mumbai'] ['Mumbai']\n",
      "{'Mumbai'} {'Mumbai'}\n",
      "['Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra', 'Maharashtra']\n",
      "{'Maharashtra'} {'Maharashtra'}\n",
      "['Hyderabad', 'State'] ['Hyderabad', 'Telangana']\n",
      "{'State', 'Hyderabad'} {'Telangana', 'Hyderabad'}\n",
      "['Odisha', 'Odisha'] ['Odisha', 'Odisha']\n",
      "{'Odisha'} {'Odisha'}\n",
      "[] ['Maharashtra', 'Maharashtra']\n",
      "set() {'Maharashtra'}\n",
      "['Mizoram'] ['Mizoram', 'Mizoram']\n",
      "{'Mizoram'} {'Mizoram'}\n",
      "['Bhubaneswar'] ['Bhubaneswar']\n",
      "{'Bhubaneswar'} {'Bhubaneswar'}\n",
      "['India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Maharashtra'] ['India']\n",
      "{'Maharashtra'} {'India'}\n",
      "['Mumbai', 'Mumbai'] ['Mumbai']\n",
      "{'Mumbai'} {'Mumbai'}\n",
      "['Bihar'] ['Bihar']\n",
      "{'Bihar'} {'Bihar'}\n",
      "['Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra', 'Maharashtra', 'Maharashtra']\n",
      "{'Maharashtra'} {'Maharashtra'}\n",
      "['Panchkula', 'Mohali', 'Chandigarh'] ['Chandigarh', 'Mohali', 'Panchkula']\n",
      "{'Mohali', 'Panchkula', 'Chandigarh'} {'Mohali', 'Panchkula', 'Chandigarh'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Telangana', 'Hyderabad', 'Rangareddy', 'Medchal', 'Khammam', 'Nalgonda', 'Manchiryala', 'Adilabad'] ['Telangana', 'Hyderabad', 'Rangareddy', 'Medchal']\n",
      "{'Medchal', 'Manchiryala', 'Rangareddy', 'Hyderabad', 'Khammam', 'Nalgonda', 'Adilabad', 'Telangana'} {'Rangareddy', 'Telangana', 'Medchal', 'Hyderabad'}\n",
      "[] ['Karnataka']\n",
      "set() {'Karnataka'}\n",
      "['country', 'country', 'country', 'country', 'country', 'country', 'country'] ['India', 'India', 'India', 'India']\n",
      "{'country'} {'India'}\n",
      "['Mumbai'] ['Mumbai']\n",
      "{'Mumbai'} {'Mumbai'}\n",
      "['Uttar Pradesh'] ['Uttar Pradesh']\n",
      "{'Uttar Pradesh'} {'Uttar Pradesh'}\n",
      "['India', 'India', 'India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "[] ['Beijing']\n",
      "set() {'Beijing'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Delhi', 'India'] ['India', 'Delhi']\n",
      "{'India', 'Delhi'} {'India', 'Delhi'}\n",
      "[] ['North Korea', 'North Korea']\n",
      "set() {'North Korea'}\n",
      "[] ['', '']\n",
      "set() {''}\n",
      "[] ['Kerala']\n",
      "set() {'Kerala'}\n",
      "['Maharashtra', 'Nagpur', 'Ahmednagar'] ['Maharashtra', 'Nagpur', 'Ahmednagar']\n",
      "{'Ahmednagar', 'Nagpur', 'Maharashtra'} {'Ahmednagar', 'Nagpur', 'Maharashtra'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Telangana', 'Telangana', 'Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India', 'India', 'India', 'India', 'India'] ['India', 'India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['New Delhi', 'New Delhi', 'New Delhi', 'New Delhi'] ['India', 'India']\n",
      "{'New Delhi'} {'India'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['Delhi', 'India'] ['Delhi', 'Delhi', 'India']\n",
      "{'India', 'Delhi'} {'India', 'Delhi'}\n",
      "['India', 'India'] ['India']\n",
      "{'India'} {'India'}\n",
      "[] ['North Korea', 'North Korea']\n",
      "set() {'North Korea'}\n",
      "[] ['Puducherry']\n",
      "set() {'Puducherry'}\n",
      "['India', 'India', 'Kerala', 'Sikkim'] ['India', 'India', 'India', 'Kerela', 'Sikkim']\n",
      "{'India', 'Kerala', 'Sikkim'} {'India', 'Kerela', 'Sikkim'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Hyderabad'] ['Telangana']\n",
      "{'Hyderabad'} {'Telangana'}\n",
      "['IIT Madras', 'India'] ['Chennai', 'Chennai']\n",
      "{'IIT Madras', 'India'} {'Chennai'}\n",
      "['India', 'India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India', 'Maharashtra', 'Delhi', 'Himachal Pradesh', 'Kerala'] ['India', 'India', 'Maharashtra', 'Delhi', 'Himachal Pradesh', 'Kerala']\n",
      "{'India', 'Himachal Pradesh', 'Maharashtra', 'Kerala', 'Delhi'} {'India', 'Himachal Pradesh', 'Maharashtra', 'Kerala', 'Delhi'}\n",
      "['Telangana', 'Hyderabad', 'Hyderabad', 'Telangana'] ['Telangana', 'Telangana', 'Hyderabad']\n",
      "{'Telangana', 'Hyderabad'} {'Telangana', 'Hyderabad'}\n",
      "['Telangana', 'Telangana', 'Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "[] ['India']\n",
      "set() {'India'}\n",
      "['New Delhi', 'New Delhi', 'New Delhi', 'New Delhi'] ['India', 'India', 'India']\n",
      "{'New Delhi'} {'India'}\n",
      "['India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Gujarat'] ['Gujarat']\n",
      "{'Gujarat'} {'Gujarat'}\n",
      "['New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi'] ['India', 'India', 'India', 'India']\n",
      "{'New Delhi'} {'India'}\n",
      "[] ['Madhya Pradesh']\n",
      "set() {'Madhya Pradesh'}\n",
      "['Karnataka', 'Haryana', 'India', 'India'] ['Karnataka', 'India', 'India']\n",
      "{'Karnataka', 'Haryana', 'India'} {'Karnataka', 'India'}\n",
      "['Telangana', 'Telangana'] ['Telangana', 'Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "[] ['India', 'India', 'Maharashtra', 'Mumbai']\n",
      "set() {'India', 'Mumbai', 'Maharashtra'}\n",
      "['New Delhi', 'India'] ['India', 'India']\n",
      "{'New Delhi', 'India'} {'India'}\n",
      "[] ['Kerela']\n",
      "set() {'Kerela'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Assam', 'Assam'] ['Assam', 'Assam']\n",
      "{'Assam'} {'Assam'}\n",
      "['India', 'India', 'India', 'India', 'India'] ['India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Manalokam'] ['India']\n",
      "{'Manalokam'} {'India'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Gujarat', 'India', 'India'] ['India', 'Gujarat']\n",
      "{'India', 'Gujarat'} {'India', 'Gujarat'}\n",
      "['Delhi'] ['Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "['Haryana'] ['Haryana']\n",
      "{'Haryana'} {'Haryana'}\n",
      "['India', 'India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Guntur', 'Palnadu'] ['Guntur', 'Palnadu']\n",
      "{'Palnadu', 'Guntur'} {'Palnadu', 'Guntur'}\n",
      "['Telangana', 'Telangana'] ['Telangana', 'Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['Kerala', 'Odisha', 'Karnataka', 'Uttar Pradesh', 'West Bengal', 'India'] ['', '', 'Kerala', 'Odisha', 'Karnataka', 'Uttar Pradesh', 'West Bengal']\n",
      "{'India', 'West Bengal', 'Uttar Pradesh', 'Karnataka', 'Kerala', 'Odisha'} {'', 'West Bengal', 'Uttar Pradesh', 'Karnataka', 'Kerala', 'Odisha'}\n",
      "['Gurukula School, Nalgonda'] ['Nalgonda District,Telangana']\n",
      "{'Gurukula School, Nalgonda'} {'Nalgonda District,Telangana'}\n",
      "['Tripura', 'Mizoram'] ['Tripuras Sepahijala', 'Mizoram']\n",
      "{'Mizoram', 'Tripura'} {'Mizoram', 'Tripuras Sepahijala'}\n",
      "['Telangana', 'Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra']\n",
      "{'Maharashtra'} {'Maharashtra'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['India', 'India', 'India', 'India'] ['India', 'India', 'India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Chandigarh', 'Mohali', 'Panchkula'] ['Chandigarh tricity', 'Chandigarh', 'Mohali', 'Panchkula']\n",
      "{'Mohali', 'Panchkula', 'Chandigarh'} {'Mohali', 'Panchkula', 'Chandigarh tricity', 'Chandigarh'}\n",
      "[] ['Pune', 'Pune', 'Pune']\n",
      "set() {'Pune'}\n",
      "['Bengaluru'] ['Bengaluru', 'Bengaluru']\n",
      "{'Bengaluru'} {'Bengaluru'}\n",
      "['Indore', 'Jabalpur', 'Madhya Pradesh'] ['state', 'Indore', 'Jabalpur']\n",
      "{'Madhya Pradesh', 'Indore', 'Jabalpur'} {'state', 'Indore', 'Jabalpur'}\n",
      "['Coimbatore'] ['Coimbatore']\n",
      "{'Coimbatore'} {'Coimbatore'}\n",
      "['Uttar Pradesh', 'Uttar Pradesh'] ['Uttar Pradesh']\n",
      "{'Uttar Pradesh'} {'Uttar Pradesh'}\n",
      "['Maharashtra', 'Mumbai', 'Maharashtra'] ['Maharashtra', 'Maharashtra', 'Maharashtra', 'Mumbai']\n",
      "{'Mumbai', 'Maharashtra'} {'Mumbai', 'Maharashtra'}\n",
      "['Ahmedabad'] ['Ahmedabad', 'Ahmedabad']\n",
      "{'Ahmedabad'} {'Ahmedabad'}\n",
      "['Bodh Gaya'] ['Bodh Gaya']\n",
      "{'Bodh Gaya'} {'Bodh Gaya'}\n",
      "['Kerala', 'India', 'India', 'India'] ['Kerela', 'India', 'India', 'India']\n",
      "{'India', 'Kerala'} {'India', 'Kerela'}\n",
      "['Telangana'] ['Telangana']\n",
      "{'Telangana'} {'Telangana'}\n",
      "['New Delhi', 'New Delhi', 'New Delhi', 'New Delhi'] ['India', 'India', 'India', 'India']\n",
      "{'New Delhi'} {'India'}\n",
      "['Telangana', 'Hyderabad', 'Rangareddy', 'Medchal Malkajigiri'] ['Telangana', 'Telangana', 'Hyderabad', 'Rangareddy', 'Medchal Malkajigiri']\n",
      "{'Rangareddy', 'Telangana', 'Medchal Malkajigiri', 'Hyderabad'} {'Rangareddy', 'Telangana', 'Medchal Malkajigiri', 'Hyderabad'}\n",
      "['Maharashtra', 'Maharashtra', 'Maharashtra', 'Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra', 'Maharashtra']\n",
      "{'Maharashtra'} {'Maharashtra'}\n",
      "['Kolkata'] ['Kolkata']\n",
      "{'Kolkata'} {'Kolkata'}\n",
      "['India', 'India', 'Kerala', 'Maharashtra'] ['India ', 'India ', 'India', 'Kerala', 'Maharashtra']\n",
      "{'India', 'Kerala', 'Maharashtra'} {'India', 'Kerala', 'India ', 'Maharashtra'}\n",
      "['Indore', 'Indore'] ['Indore', 'Indore']\n",
      "{'Indore'} {'Indore'}\n",
      "['India', 'India'] ['India', 'India', 'India', 'India', 'Kerala']\n",
      "{'India'} {'India', 'Kerala'}\n",
      "['Vadodara'] ['Vadodara', 'Vadodara']\n",
      "{'Vadodara'} {'Vadodara'}\n",
      "['Chennai', 'Chengalpattu'] ['Chennai ', 'Chengalpattu', '']\n",
      "{'Chennai', 'Chengalpattu'} {'Chennai ', '', 'Chengalpattu'}\n",
      "['Alappuzha'] ['Alappuzha']\n",
      "{'Alappuzha'} {'Alappuzha'}\n",
      "['Pune'] ['Pune']\n",
      "{'Pune'} {'Pune'}\n",
      "[] ['Maharashtra']\n",
      "set() {'Maharashtra'}\n",
      "['Eluru', 'Eluru'] ['AP', 'AP']\n",
      "{'Eluru'} {'AP'}\n",
      "[] ['India', 'Kerala', 'Tamil Nadu', 'Odisha', 'Haryana']\n",
      "set() {'India', 'Haryana', 'Kerala', 'Odisha', 'Tamil Nadu'}\n",
      "['Bengal'] ['Bengal', 'Bengal']\n",
      "{'Bengal'} {'Bengal'}\n",
      "['India', 'India', 'India', 'India'] ['India', 'India', 'India', 'India', 'Kerala']\n",
      "{'India'} {'India', 'Kerala'}\n",
      "['Delhi'] ['Delhi']\n",
      "{'Delhi'} {'Delhi'}\n",
      "[] ['India', 'World', 'World']\n",
      "set() {'India', 'World'}\n",
      "['India'] ['India', 'India']\n",
      "{'India'} {'India'}\n",
      "['Mizoram'] ['Mizoram', 'Mizoram']\n",
      "{'Mizoram'} {'Mizoram'}\n",
      "['Maharashtra', 'Maharashtra'] ['Maharashtra', 'Maharashtra', 'Maharashtra']\n",
      "{'Maharashtra'} {'Maharashtra'}\n",
      "['Erode'] ['Erode', 'Erode']\n",
      "{'Erode'} {'Erode'}\n",
      "['Madhya Pradesh'] ['Madhya Pradesh', 'Madhya Pradesh']\n",
      "{'Madhya Pradesh'} {'Madhya Pradesh'}\n",
      "['Nagaland'] ['Nagaland', 'Nagaland']\n",
      "{'Nagaland'} {'Nagaland'}\n",
      "['India'] ['India']\n",
      "{'India'} {'India'}\n",
      "['Mizoram', 'Manipur', 'Imphal', 'Imphal'] ['Mizoram', 'Manipur', '', '']\n",
      "{'Mizoram', 'Imphal', 'Manipur'} {'Mizoram', '', 'Manipur'}\n",
      "Location NER:\n",
      "Precision: 0.7430767061477722 Recall: 0.7195149464184999 F1: 0.7244238981548624\n"
     ]
    }
   ],
   "source": [
    "new_df['locations_gt'] = [[event['Location'] for event in events] for events in new_df['GT_Events']]\n",
    "new_df['locations_pred'] = new_df['events'].apply(lambda x: [i['location'] for i in x])\n",
    "print(new_df.shape)\n",
    "avg_precision = 0; avg_recall = 0; avg_f1 = 0\n",
    "for i in range(len(new_df)):\n",
    "    print(new_df['locations_pred'][i], new_df['locations_gt'][i])\n",
    "    precision, recall, f1, exact_match = event_eval.precision_recall_method_2(new_df['locations_pred'][i], new_df['locations_gt'][i])\n",
    "    avg_precision += precision\n",
    "    avg_recall += recall\n",
    "    avg_f1 += f1\n",
    "    \n",
    "avg_precision /= len(new_df)\n",
    "avg_recall /= len(new_df)\n",
    "avg_f1 /= len(new_df)\n",
    "\n",
    "print('Location NER:')\n",
    "print('Precision:', avg_precision, 'Recall:', avg_recall, 'F1:', avg_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
